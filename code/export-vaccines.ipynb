{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a9b142a8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yonatan/.local/share/jupyter/runtime/kernel-v2-16790BZ41MzrM7HGj.json\n"
     ]
    }
   ],
   "source": [
    "from jupyter_client import find_connection_file\n",
    "connection_file = find_connection_file()\n",
    "print(connection_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b04e9617",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import papermill as pm\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.tracebacklimit = 0\n",
    "def exception_handler(exception_type, exception, traceback):\n",
    "    # All your trace are belong to us!\n",
    "    # your format\n",
    "    print(f\"{exception_type.__name__}, {exception}\")\n",
    "\n",
    "sys.excepthook = exception_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "91ebcd16",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "dataset_col = \"Dataset\"\n",
    "uid_col = \"uid\"\n",
    "age_col = \"Age\"\n",
    "day_col = \"Day\"\n",
    "response_col = \"Response\"\n",
    "immage_col = \"IMMAGE\"\n",
    "strain_col = 'Strain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "68774cf3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Read in Data and drop missing values\n",
    "df = pd.read_csv(\"../data/all_vaccines.csv\")\n",
    "df.dropna(inplace=True, subset=[immage_col, dataset_col, day_col, response_col])\n",
    "datasets = df\n",
    "\n",
    "\n",
    "# Plot distribution of N values\n",
    "N_vals = df[[dataset_col, uid_col]].groupby(dataset_col, as_index=False)[uid_col].nunique()\n",
    "N_vals = N_vals.rename(columns={uid_col: \"N\"})\n",
    "\n",
    "# Narrow to large datasets only\n",
    "bNarrow = False\n",
    "N_vals = N_vals.loc[N_vals[\"N\"] > 70]\n",
    "if bNarrow:\n",
    "    filtered_df = df.loc[df[\"Dataset\"].isin(N_vals[\"Dataset\"])]\n",
    "dataset_names = filtered_df[\"Dataset\"].unique().astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "01a38b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All papers\n",
    "dataset_day_dicts = [\n",
    "        {\"Dataset\": \"GSE125921.SDY1529\", \"Days\": ['FC', 'D84']},\n",
    "        {\"Dataset\": \"GSE13485.SDY1264\", \"Days\": ['D60']},\n",
    "        {\"Dataset\": \"GSE13699.SDY1289\", \"Days\": ['D28']},\n",
    "        {\"Dataset\": \"GSE169159\", \"Days\": ['FC.D42', 'D42']},\n",
    "        {\"Dataset\": \"GSE41080.SDY212\", \"Days\": ['HAI.D28']},\n",
    "        {\"Dataset\": \"GSE45735.SDY224\", \"Days\": ['HAI.D21']},\n",
    "        {\"Dataset\": \"GSE47353.SDY80\", \"Days\": ['D70.nAb', 'FC.D70.nAb']},\n",
    "        {\"Dataset\": \"GSE48018.SDY1276\", \"Days\": ['nAb.D28', 'nAb.FC']},\n",
    "        {\"Dataset\": \"GSE48023.SDY1276\", \"Days\": ['nAb.FC', 'nAb.D14']},\n",
    "        {\"Dataset\": \"GSE59635.SDY63\", \"Days\": ['HAI.D28']},\n",
    "        {\"Dataset\": \"GSE59654.SDY180\", \"Days\": ['FC.HAI', 'HAI.D28']},\n",
    "        {\"Dataset\": \"GSE59654.SDY404\", \"Days\": ['FC.HAI', 'HAI.D28']},\n",
    "        {\"Dataset\": \"GSE59654.SDY520\", \"Days\": ['FC.HAI', 'HAI.D28']},\n",
    "        {\"Dataset\": \"GSE59743.SDY400\", \"Days\": ['FC.HAI', 'HAI.D28']},\n",
    "        {\"Dataset\": \"GSE65834.SDY1328\", \"Days\": ['D7', 'FC']},\n",
    "        {\"Dataset\": \"GSE79396.SDY984\", \"Days\": ['D28', 'FC.D28']},\n",
    "        {\"Dataset\": \"GSE82152.SDY1294\", \"Days\": ['D28', 'FC']},\n",
    "        {\"Dataset\": \"SDY1325\", \"Days\": ['FC.D28', 'D28']},\n",
    "        {\"Dataset\": \"SDY296\", \"Days\": ['D28.nAb', 'FC.nAb']},\n",
    "        {\"Dataset\": \"SDY67\", \"Days\": ['nAb.D28', 'FC.D28.nAb']},\n",
    "        {\"Dataset\": \"SDY89\", \"Days\": ['D28']}\n",
    "]\n",
    "\n",
    "datasets = pd.DataFrame(dataset_day_dicts)\n",
    "dataset_names = datasets[dataset_col].unique().astype(str)\n",
    "filtered_df = df.loc[df[\"Dataset\"].isin(dataset_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "70efdfc4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Keep only Influenze datasets for now\n",
    "# influenza_sets = ['GSE41080.SDY212', 'GSE48018.SDY1276', 'GSE48023.SDY1276', 'SDY67', 'GSE125921.SDY1529', 'GSE45735.SDY224', 'GSE47353.SDY80', 'GSE48023.SDY1276', 'GSE59635.SDY63', 'GSE59654.SDY404', 'GSE59743.SDY400', 'SDY296']\n",
    "influenza_dicts = [\n",
    "        {\"Dataset\": \"GSE41080.SDY212\", \"Days\": [\"FC.HAI\", \"HAI.D28\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"HAI.MFC\"},\n",
    "        {\"Dataset\": \"GSE45735.SDY224\", \"Days\": [\"FC.HAI\", \"HAI.D21\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"HAI.MFC\"},\n",
    "        # start with sets that have a HAI measurement\n",
    "        # {\"Dataset\": \"GSE47353.SDY80\", \"Days\": [\"D70.nAb\", \"FC.D70.nAb\"], \"Day0\": \"D0.nAb\"},\n",
    "        {\"Dataset\": \"GSE48018.SDY1276\", \"Days\": [\"HAI.D28\", \"HAI.FC\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"HAI.MFC\"},\n",
    "        {\"Dataset\": \"GSE48023.SDY1276\", \"Days\": [\"HAI.FC\", \"HAI.D28\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"HAI.MFC\"},\n",
    "        {\"Dataset\": \"GSE59635.SDY63\", \"Days\": [\"FC\", \"HAI.D28\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"HAI.MFC\"},\n",
    "        {\"Dataset\": \"GSE59654.SDY404\", \"Days\": [\"HAI.D28\", \"FC.HAI\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"HAI.MFC\"},\n",
    "        {\"Dataset\": \"GSE59743.SDY400\", \"Days\": [\"FC.HAI\", \"HAI.D28\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"HAI.MFC\"},\n",
    "        # Need to calculate MFC individually for this one\n",
    "        # {\"Dataset\": \"SDY296\", \"Days\": [\"D28.HAI\", \"FC.HAI\"], \"Day0\": \"D0.HAI\"},\n",
    "        {\"Dataset\": \"SDY67\", \"Days\": [\"FC.D28.HAI\", \"HAI.D28\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"HAI.MFC\"},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d185e08e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "bAdjustMFC = False\n",
    "bDiscardSeroprotected = False\n",
    "bInfluenza = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c06bd35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if bInfluenza:\n",
    "    datasets = pd.DataFrame(influenza_dicts)\n",
    "    dataset_names = datasets[\"Dataset\"].unique().astype(str)\n",
    "    filtered_df = df.loc[df[\"Dataset\"].isin(dataset_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "50cc975b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GSE41080.SDY212'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ce3f8778",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSE41080.SDY212\n",
      "FC.HAI\n",
      "['B/Florida/4/2006' 'A/Brisbane/10/2007' 'A/Brisbane/59/2007']\n",
      "exporting GSE41080.SDY212, strain no. 0: B_Florida_4_2006, day: FC.HAI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook export/GSE41080.SDY212_B_Florida_4_2006_FC.HAI_test_analysis.ipynb to html\n",
      "[NbConvertApp] WARNING | Alternative text is missing on 7 image(s).\n",
      "[NbConvertApp] Writing 819366 bytes to export/GSE41080.SDY212_B_Florida_4_2006_Adjusted_MFC_test.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exporting GSE41080.SDY212, strain no. 1: A_Brisbane_10_2007, day: FC.HAI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook export/GSE41080.SDY212_A_Brisbane_10_2007_FC.HAI_test_analysis.ipynb to html\n",
      "[NbConvertApp] WARNING | Alternative text is missing on 7 image(s).\n",
      "[NbConvertApp] Writing 819368 bytes to export/GSE41080.SDY212_A_Brisbane_10_2007_Adjusted_MFC_test.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exporting GSE41080.SDY212, strain no. 2: A_Brisbane_59_2007, day: FC.HAI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook export/GSE41080.SDY212_A_Brisbane_59_2007_FC.HAI_test_analysis.ipynb to html\n",
      "[NbConvertApp] WARNING | Alternative text is missing on 7 image(s).\n",
      "[NbConvertApp] Writing 819368 bytes to export/GSE41080.SDY212_A_Brisbane_59_2007_Adjusted_MFC_test.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAI.D28\n",
      "['A/Brisbane/10/2007' 'B/Florida/4/2006' 'A/Brisbane/59/2007']\n",
      "exporting GSE41080.SDY212, strain no. 0: A_Brisbane_10_2007, day: HAI.D28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook export/GSE41080.SDY212_A_Brisbane_10_2007_HAI.D28_test_analysis.ipynb to html\n",
      "[NbConvertApp] WARNING | Alternative text is missing on 7 image(s).\n",
      "[NbConvertApp] Writing 819370 bytes to export/GSE41080.SDY212_A_Brisbane_10_2007_Adjusted_MFC_test.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exporting GSE41080.SDY212, strain no. 1: B_Florida_4_2006, day: HAI.D28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook export/GSE41080.SDY212_B_Florida_4_2006_HAI.D28_test_analysis.ipynb to html\n",
      "[NbConvertApp] WARNING | Alternative text is missing on 7 image(s).\n",
      "[NbConvertApp] Writing 819368 bytes to export/GSE41080.SDY212_B_Florida_4_2006_Adjusted_MFC_test.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exporting GSE41080.SDY212, strain no. 2: A_Brisbane_59_2007, day: HAI.D28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook export/GSE41080.SDY212_A_Brisbane_59_2007_HAI.D28_test_analysis.ipynb to html\n",
      "[NbConvertApp] WARNING | Alternative text is missing on 7 image(s).\n",
      "[NbConvertApp] Writing 819370 bytes to export/GSE41080.SDY212_A_Brisbane_59_2007_Adjusted_MFC_test.html\n"
     ]
    }
   ],
   "source": [
    "# Loop through each combination of dataset and strain\n",
    "for dataset_name in dataset_names[:1]:\n",
    "        dataset = datasets.loc[datasets[dataset_col] == dataset_name]\n",
    "        filtered_df = filtered_df.loc[filtered_df[dataset_col] == dataset_name]\n",
    "        print(dataset_name)\n",
    "        days = dataset[\"Days\"][0]\n",
    "        for day in days:\n",
    "                print(day)\n",
    "                day_mask = filtered_df[day_col] == day\n",
    "                name_mask = filtered_df[dataset_col] == dataset_name\n",
    "                data = filtered_df.loc[(name_mask) & (day_mask)].reset_index()\n",
    "                strains = data[strain_col].unique()\n",
    "                print(strains)\n",
    "                for strain_index in range(len(strains)):\n",
    "                        strain_name = strains[strain_index].replace(\"/\", \"_\").replace(\" \", \"_\")\n",
    "                        print(f'exporting {dataset_name}, strain no. {strain_index}: {strain_name}, day: {day}')\n",
    "                        # Define parameters for dataset and strain\n",
    "                        parameters = {\n",
    "                                      \"dataset_name\": dataset_name,\n",
    "                                      \"strain_index\": strain_index,\n",
    "                                      \"day\": day,\n",
    "                                      \"bAdjustMFC\" : bAdjustMFC,\n",
    "                                      \"bDiscardSeroprotected\" : bDiscardSeroprotected,\n",
    "                                      \"bInfluenza\": bInfluenza,\n",
    "                                      \"influenza_dicts\": influenza_dicts,\n",
    "                                      }\n",
    "\n",
    "                        # EXECUTE the notebook with specific parameters\n",
    "                        output_notebook = f\"export/{dataset_name}_{strain_name}_{day}_test_analysis.ipynb\"\n",
    "                        try:\n",
    "                                pm.execute_notebook(\n",
    "                                        input_path=\"vaccines-4.ipynb\",\n",
    "                                        output_path=output_notebook,\n",
    "                                        parameters=parameters,\n",
    "                                        prepare_only=True\n",
    "                                )\n",
    "                        except:\n",
    "                                print (f\"******\\nCaught exception when runnnig {output_notebook}\\n******\\n\")\n",
    "                        # Export the executed notebook to HTML\n",
    "                        # output_html = f\"{dataset_name}_{strain_name}_{day}_discard_seroprotected.html\"\n",
    "                        output_html = f\"{dataset_name}_{strain_name}_{day}_test.html\"\n",
    "                        os.system(f\"jupyter nbconvert --execute --no-input --to html {output_notebook} --output {output_html}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9fe0ab4f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "# Loop through each combination of dataset and strain\n",
    "# for dataset_name in dataset_names[:1]:\n",
    "#         dataset = datasets.loc[datasets[dataset_col] == dataset_name]\n",
    "#         filtered_df = filtered_df.loc[filtered_df[dataset_col] == dataset_name]\n",
    "#         print(dataset_name)\n",
    "#         if bAdjustMFC:\n",
    "#             days = dataset[\"DayMFC\"]\n",
    "#         else:\n",
    "#             days = dataset[\"Days\"]\n",
    "\n",
    "#         for day in days:\n",
    "#                 print(day)\n",
    "#                 day_mask = filtered_df[day_col] == day\n",
    "#                 name_mask = filtered_df[dataset_col] == dataset_name\n",
    "#                 data = filtered_df.loc[(name_mask) & (day_mask)].reset_index()\n",
    "#                 if bAdjustMFC:\n",
    "#                         strains = \"Influenza\"\n",
    "#                 else:\n",
    "#                         strains = data[strain_col].unique()\n",
    "#                 print(strains)\n",
    "#                 for strain_index in range(len(strains)):\n",
    "#                         strain_name = strains[strain_index].replace(\"/\", \"_\").replace(\" \", \"_\")\n",
    "#                         print(f'exporting {dataset_name}, strain no. {strain_index}: {strain_name}, day: {day}')\n",
    "#                         # Define parameters for dataset and strain\n",
    "#                         parameters = {\n",
    "#                                       \"dataset_name\": dataset_name,\n",
    "#                                       \"strain_index\": strain_index,\n",
    "#                                       \"day\": day,\n",
    "#                                       \"day0\": dataset[\"Day0\"],\n",
    "#                                       \"dayMFC\": dataset[\"DayMFC\"],\n",
    "#                                       \"bInfluenza\": bInfluenza,\n",
    "#                                       \"bAdjustMFC\" : bAdjustMFC,\n",
    "#                                       \"influenza_dicts\": influenza_dicts,\n",
    "#                                       }\n",
    "\n",
    "#                         # EXECUTE the notebook with specific parameters\n",
    "#                         day_string = f'{\"Adjusted_MFC\" if bAdjustMFC else day}'\n",
    "#                         output_notebook = f\"export/{dataset_name}_{strain_name}_{day_string}_analysis.ipynb\"\n",
    "#                         try:\n",
    "#                                 pm.execute_notebook(\n",
    "#                                         input_path=\"vaccines-4.ipynb\",\n",
    "#                                         output_path=output_notebook,\n",
    "#                                         parameters=parameters,\n",
    "#                                         prepare_only=True\n",
    "#                                 )\n",
    "#                         except:\n",
    "#                                 print (f\"******\\nCaught exception when runnnig {output_notebook}\\n******\\n\")\n",
    "#                         # Export the executed notebook to HTML\n",
    "#                         # output_html = f\"{dataset_name}_{strain_name}_{day}_discard_seroprotected.html\"\n",
    "#                         output_html = f\"{dataset_name}_{strain_name}_{day_string}.html\"\n",
    "#                         os.system(f\"jupyter nbconvert --execute --no-input --to html {output_notebook} --output {output_html}\")\n",
    "\n",
    "# # %%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
