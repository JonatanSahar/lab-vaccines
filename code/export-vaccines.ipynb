{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "118e5db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yonatan/.local/share/jupyter/runtime/kernel-v2-16790ZPmNUueXNcqf.json\n"
     ]
    }
   ],
   "source": [
    "from jupyter_client import find_connection_file\n",
    "connection_file = find_connection_file()\n",
    "print(connection_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "741e0297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import papermill as pm\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.tracebacklimit = 0\n",
    "def exception_handler(exception_type, exception, traceback):\n",
    "    # All your trace are belong to us!\n",
    "    # your format\n",
    "    print(f\"{exception_type.__name__}, {exception}\")\n",
    "\n",
    "#sys.excepthook = exception_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b07ef27c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "dataset_col = \"Dataset\"\n",
    "uid_col = \"uid\"\n",
    "age_col = \"Age\"\n",
    "day_col = \"Day\"\n",
    "response_col = \"Response\"\n",
    "immage_col = \"IMMAGE\"\n",
    "strain_col = 'Strain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "13a18c40",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Read in Data and drop missing values\n",
    "df = pd.read_csv(\"../data/all_vaccines.csv\")\n",
    "df.dropna(inplace=True, subset=[immage_col, dataset_col, day_col, response_col])\n",
    "dataset_names = df[\"Dataset\"].unique().astype(str)\n",
    "\n",
    "# Plot distribution of N values\n",
    "N_vals = df[[dataset_col, uid_col]].groupby(dataset_col, as_index=False)[uid_col].nunique()\n",
    "N_vals = N_vals.rename(columns={uid_col: \"N\"})\n",
    "\n",
    "# Narrow to large datasets only\n",
    "bNarrow = False\n",
    "N_vals = N_vals.loc[N_vals[\"N\"] > 70]\n",
    "if bNarrow:\n",
    "    filtered_df = df.loc[df[\"Dataset\"].isin(N_vals[\"Dataset\"])]\n",
    "    dataset_names = filtered_df[\"Dataset\"].unique().astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1724c1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All papers\n",
    "dataset_day_dicts = [\n",
    "        {\"Dataset\": \"GSE125921.SDY1529\", \"Days\": ['FC', 'D84']},\n",
    "        {\"Dataset\": \"GSE13485.SDY1264\", \"Days\": ['D60']},\n",
    "        {\"Dataset\": \"GSE13699.SDY1289\", \"Days\": ['D28']},\n",
    "        {\"Dataset\": \"GSE169159\", \"Days\": ['FC.D42', 'D42']},\n",
    "        {\"Dataset\": \"GSE41080.SDY212\", \"Days\": ['HAI.D28']},\n",
    "        {\"Dataset\": \"GSE45735.SDY224\", \"Days\": ['HAI.D21']},\n",
    "        {\"Dataset\": \"GSE47353.SDY80\", \"Days\": ['D70.nAb', 'FC.D70.nAb']},\n",
    "        {\"Dataset\": \"GSE48018.SDY1276\", \"Days\": ['nAb.D28', 'nAb.FC']},\n",
    "        {\"Dataset\": \"GSE48023.SDY1276\", \"Days\": ['nAb.FC', 'nAb.D14']},\n",
    "        {\"Dataset\": \"GSE59635.SDY63\", \"Days\": ['HAI.D28']},\n",
    "        {\"Dataset\": \"GSE59654.SDY180\", \"Days\": ['FC.HAI', 'HAI.D28']},\n",
    "        {\"Dataset\": \"GSE59654.SDY404\", \"Days\": ['FC.HAI', 'HAI.D28']},\n",
    "        {\"Dataset\": \"GSE59654.SDY520\", \"Days\": ['FC.HAI', 'HAI.D28']},\n",
    "        {\"Dataset\": \"GSE59743.SDY400\", \"Days\": ['FC.HAI', 'HAI.D28']},\n",
    "        {\"Dataset\": \"GSE65834.SDY1328\", \"Days\": ['D7', 'FC']},\n",
    "        {\"Dataset\": \"GSE79396.SDY984\", \"Days\": ['D28', 'FC.D28']},\n",
    "        {\"Dataset\": \"GSE82152.SDY1294\", \"Days\": ['D28', 'FC']},\n",
    "        {\"Dataset\": \"SDY1325\", \"Days\": ['FC.D28', 'D28']},\n",
    "        {\"Dataset\": \"SDY296\", \"Days\": ['D28.nAb', 'FC.nAb']},\n",
    "        {\"Dataset\": \"SDY67\", \"Days\": ['nAb.D28', 'FC.D28.nAb']},\n",
    "        {\"Dataset\": \"SDY89\", \"Days\": ['D28']}\n",
    "]\n",
    "\n",
    "datasets = pd.DataFrame(dataset_day_dicts)\n",
    "dataset_names = datasets[dataset_col].unique().astype(str)\n",
    "filtered_df = df.loc[df[\"Dataset\"].isin(dataset_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d7d5390f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Keep only Influenze datasets for now\n",
    "# influenza_sets = ['GSE41080.SDY212', 'GSE48018.SDY1276', 'GSE48023.SDY1276', 'SDY67', 'GSE125921.SDY1529', 'GSE45735.SDY224', 'GSE47353.SDY80', 'GSE48023.SDY1276', 'GSE59635.SDY63', 'GSE59654.SDY404', 'GSE59743.SDY400', 'SDY296']\n",
    "influenza_dicts = [\n",
    "        {\"Dataset\": \"GSE41080.SDY212\", \"Days\": [\"FC.HAI\", \"HAI.D28\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"HAI.MFC\"},\n",
    "        {\"Dataset\": \"GSE48018.SDY1276\", \"Days\": [\"HAI.D28\", \"HAI.FC\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"HAI.MFC\"},\n",
    "        {\"Dataset\": \"GSE59654.SDY404\", \"Days\": [\"HAI.D28\", \"FC.HAI\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"HAI.MFC\"},\n",
    "        {\"Dataset\": \"GSE59743.SDY400\", \"Days\": [\"FC.HAI\", \"HAI.D28\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"HAI.MFC\"},\n",
    "        {\"Dataset\": \"SDY67\", \"Days\": [\"FC.D28.HAI\", \"HAI.D28\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"HAI.MFC\"},\n",
    "        {\"Dataset\": \"GSE59635.SDY63\", \"Days\": [\"FC\", \"HAI.D28\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"HAI.MFC\"},\n",
    "        # Five subjects only\n",
    "        # {\"Dataset\": \"GSE45735.SDY224\", \"Days\": [\"FC.HAI\", \"HAI.D21\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"HAI.MFC\"},\n",
    "        # Doesn't have a HAI measurement\n",
    "        # {\"Dataset\": \"GSE47353.SDY80\", \"Days\": [\"D70.nAb\", \"FC.D70.nAb\"], \"Day0\": \"D0.nAb\"},\n",
    "        # Need to calculate MFC individually for these\n",
    "        # {\"Dataset\": \"GSE48023.SDY1276\", \"Days\": [\"HAI.FC\", \"HAI.D28\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"HAI.MFC\"},\n",
    "        # {\"Dataset\": \"SDY296\", \"Days\": [\"D28.HAI\", \"FC.HAI\"], \"Day0\": \"D0.HAI\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2298203e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "bInfluenza = True\n",
    "bAdjustMFC = True\n",
    "bDiscardSeroprotected = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "51dff053",
   "metadata": {},
   "outputs": [],
   "source": [
    "if bInfluenza:\n",
    "    datasets = pd.DataFrame(influenza_dicts)\n",
    "    dataset_names = datasets[\"Dataset\"].unique().astype(str)\n",
    "    filtered_df = df.loc[df[\"Dataset\"].isin(dataset_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "48fd901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each combination of dataset and strain\n",
    "if bAdjustMFC == False:\n",
    "    for dataset_name in dataset_names[:1]:\n",
    "            dataset = datasets.loc[datasets[dataset_col] == dataset_name]\n",
    "            filtered_df = filtered_df.loc[filtered_df[dataset_col] == dataset_name]\n",
    "            print(dataset_name)\n",
    "            days = dataset[\"Days\"].iloc[0]\n",
    "            for day in days:\n",
    "                    print(day)\n",
    "                    day_mask = filtered_df[day_col] == day\n",
    "                    name_mask = filtered_df[dataset_col] == dataset_name\n",
    "                    data = filtered_df.loc[(name_mask) & (day_mask)].reset_index()\n",
    "                    strains = data[strain_col].unique()\n",
    "                    print(strains)\n",
    "                    for strain_index in range(len(strains)):\n",
    "                            strain_name = strains[strain_index].replace(\"/\", \"_\").replace(\" \", \"_\")\n",
    "                            print(f'exporting {dataset_name}, strain no. {strain_index}: {strain_name}, day: {day}')\n",
    "                            # Define parameters for dataset and strain\n",
    "                            parameters = {\n",
    "                                        \"bAdjustMFC\" : bAdjustMFC,\n",
    "                                        \"bDiscardSeroprotected\" : bDiscardSeroprotected,\n",
    "                                        \"bInfluenza\": bInfluenza,\n",
    "                                        \"dataset_name\": dataset_name,\n",
    "                                        \"strain_index\": strain_index,\n",
    "                                        \"day\": day,\n",
    "                                        \"influenza_dicts\": influenza_dicts\n",
    "                                        }\n",
    "\n",
    "                            # EXECUTE the notebook with specific parameters\n",
    "                            output_notebook = f\"export/{dataset_name}_{strain_name}_{day}_analysis.ipynb\"\n",
    "                            try:\n",
    "                                    pm.execute_notebook(\n",
    "                                            input_path=\"vaccines-4.ipynb\",\n",
    "                                            output_path=output_notebook,\n",
    "                                            parameters=parameters,\n",
    "                                            prepare_only=True\n",
    "                                    )\n",
    "                            except:\n",
    "                                    print (f\"******\\nCaught exception when runnnig {output_notebook}\\n******\\n\")\n",
    "                            # Export the executed notebook to HTML\n",
    "                            # output_html = f\"{dataset_name}_{strain_name}_{day}_discard_seroprotected.html\"\n",
    "                            output_html = f\"{dataset_name}_{strain_name}_{day}.html\"\n",
    "                            os.system(f\"jupyter nbconvert --execute --no-input --to html {output_notebook} --output {output_html}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e07e188c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSE41080.SDY212\n",
      "exporting GSE41080.SDY212, using adjusted MFC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook export/GSE41080.SDY212_Influenza_Adjusted_MFC_analysis.ipynb to html\n",
      "[NbConvertApp] WARNING | Alternative text is missing on 7 image(s).\n",
      "[NbConvertApp] Writing 817788 bytes to export/GSE41080.SDY212_Influenza_Adjusted_MFC.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSE48018.SDY1276\n",
      "exporting GSE48018.SDY1276, using adjusted MFC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook export/GSE48018.SDY1276_Influenza_Adjusted_MFC_analysis.ipynb to html\n",
      "[NbConvertApp] WARNING | Alternative text is missing on 7 image(s).\n",
      "[NbConvertApp] Writing 846226 bytes to export/GSE48018.SDY1276_Influenza_Adjusted_MFC.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSE59654.SDY404\n",
      "exporting GSE59654.SDY404, using adjusted MFC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook export/GSE59654.SDY404_Influenza_Adjusted_MFC_analysis.ipynb to html\n",
      "[NbConvertApp] WARNING | Alternative text is missing on 7 image(s).\n",
      "[NbConvertApp] Writing 786416 bytes to export/GSE59654.SDY404_Influenza_Adjusted_MFC.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSE59743.SDY400\n",
      "exporting GSE59743.SDY400, using adjusted MFC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook export/GSE59743.SDY400_Influenza_Adjusted_MFC_analysis.ipynb to html\n",
      "[NbConvertApp] WARNING | Alternative text is missing on 7 image(s).\n",
      "[NbConvertApp] Writing 748900 bytes to export/GSE59743.SDY400_Influenza_Adjusted_MFC.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDY67\n",
      "exporting SDY67, using adjusted MFC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook export/SDY67_Influenza_Adjusted_MFC_analysis.ipynb to html\n",
      "[NbConvertApp] WARNING | Alternative text is missing on 7 image(s).\n",
      "[NbConvertApp] Writing 845059 bytes to export/SDY67_Influenza_Adjusted_MFC.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSE59635.SDY63\n",
      "exporting GSE59635.SDY63, using adjusted MFC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook export/GSE59635.SDY63_Influenza_Adjusted_MFC_analysis.ipynb to html\n",
      "[NbConvertApp] WARNING | Alternative text is missing on 7 image(s).\n",
      "[NbConvertApp] Writing 740059 bytes to export/GSE59635.SDY63_Influenza_Adjusted_MFC.html\n"
     ]
    }
   ],
   "source": [
    "# Loop through each combination of dataset and strain\n",
    "if bAdjustMFC == True:\n",
    "    for dataset_name in dataset_names:\n",
    "            dataset = datasets.loc[datasets[dataset_col] == dataset_name]\n",
    "            filtered_df = filtered_df.loc[filtered_df[dataset_col] == dataset_name]\n",
    "            print(dataset_name)\n",
    "            strain_name = \"Influenza\"\n",
    "            print(f'exporting {dataset_name}, using adjusted MFC')\n",
    "            # Define parameters for dataset and strain\n",
    "            parameters = {\n",
    "                    \"bInfluenza\": bInfluenza,\n",
    "                    \"bAdjustMFC\" : bAdjustMFC,\n",
    "                    \"bDiscardSeroprotected\" : bDiscardSeroprotected,\n",
    "                    \"dataset_name\": dataset_name,\n",
    "                    \"day0\": dataset[\"Day0\"].iloc[0],\n",
    "                    \"dayMFC\": dataset[\"DayMFC\"].iloc[0],\n",
    "                    \"influenza_dicts\": influenza_dicts\n",
    "                    }\n",
    "\n",
    "            # EXECUTE the notebook with specific parameters\n",
    "            day_string = 'Adjusted_MFC'\n",
    "            output_notebook = f\"export/{dataset_name}_{strain_name}_{day_string}_analysis.ipynb\"\n",
    "            try:\n",
    "                pm.execute_notebook(\n",
    "                        input_path=\"vaccines-4.ipynb\",\n",
    "                        output_path=output_notebook,\n",
    "                        parameters=parameters,\n",
    "                        prepare_only=True\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print (f\"******\\nCaught exception when runnnig {output_notebook}\\n******\\n\")\n",
    "                print(e)\n",
    "            # Export the executed notebook to HTML\n",
    "            output_html = f\"{dataset_name}_{strain_name}_{day_string}.html\"\n",
    "            os.system(f\"jupyter nbconvert --execute --no-input --to html {output_notebook} --output {output_html}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
