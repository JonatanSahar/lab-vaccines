{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d534138",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from jupyter_client import find_connection_file\n",
    "connection_file = find_connection_file()\n",
    "print(connection_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc632626",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "#Plotting related\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='notebook'\n",
    "\n",
    "# Scikit-learn related imports\n",
    "import pyarrow\n",
    "import pandas as pd\n",
    "pd.options.mode.copy_on_write = True\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import randint, ttest_ind\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb5f7e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "dataset_col = \"Dataset\"\n",
    "uid_col = \"uid\"\n",
    "age_col = \"Age\"\n",
    "day_col = \"Day\"\n",
    "response_col = \"Response\"\n",
    "immage_col = \"IMMAGE\"\n",
    "strain_col = 'Strain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a392e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_dir():\n",
    "   # Define the starting directory\n",
    "   current_dir = os.getcwd()\n",
    "\n",
    "   # Traverse up the directory tree until we find a directory named \"data\"\n",
    "   while current_dir != \"/\":\n",
    "      if \"data\" in os.listdir(current_dir):\n",
    "         data_dir = os.path.join(current_dir, \"data\")\n",
    "         return data_dir\n",
    "      current_dir = os.path.dirname(current_dir)\n",
    "   else:\n",
    "      print(\"Directory 'data' not found in the parent directories.\")\n",
    "      raise()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cf592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data and drop missing values\n",
    "data_dir = get_data_dir()\n",
    "df = pd.read_csv(os.path.join(data_dir, \"../data/all_vaccines.csv\"))\n",
    "df.dropna(inplace=True, subset=[immage_col, dataset_col, day_col, response_col])\n",
    "\n",
    "dataset_names = df.Dataset.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6f1fa0",
   "metadata": {},
   "source": [
    "##### Plot distribution of studies' N values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c00ef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of N values\n",
    "N_vals = df[[dataset_col, uid_col]].groupby(dataset_col, as_index=False)[uid_col].nunique()\n",
    "N_vals = N_vals.rename(columns={uid_col: \"N\"})\n",
    "sns.histplot(N_vals.N)\n",
    "plt.title(\"N values across studies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8bae2a",
   "metadata": {},
   "source": [
    "##### Narrow to large datasets only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b8e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrow N_v to large datasets only\n",
    "N_vals = N_vals.loc[N_vals[\"N\"]> 70]\n",
    "datasets = df.loc[df[\"Dataset\"].isin(N_vals[\"Dataset\"])]\n",
    "dataset_names = datasets[\"Dataset\"].unique()\n",
    "N_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4783ab0d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Examine available days per dataset\n",
    "days = datasets[[dataset_col, uid_col, day_col]].groupby(dataset_col, as_index=False)[day_col].unique()\n",
    "t = pd.Series(days.loc[[True, False, False, False], \"Day\"])\n",
    "# with pd.option_context('display.max_colwidth', None):\n",
    "#    for index, row in days.iterrows():\n",
    "#     print(f\"Dataset: {row['Dataset']}\\nDays: {row['Day']}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200b2240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect day info from papers here\n",
    "dataset_day_dict = {}\n",
    "\n",
    "dataset_day_dict[\"GSE41080.SDY212\"] = \"HAI.D28\"\n",
    "dataset_day_dict[\"GSE48018.SDY1276\"] = \"nAb.D28\"\n",
    "dataset_day_dict[\"GSE48023.SDY1276\"] = \"nAb.D28\"\n",
    "dataset_day_dict[\"SDY67\"] = \"nAb.D28\"\n",
    "# dataset_day_dict[dataset_names[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca602584",
   "metadata": {},
   "source": [
    "##### Narrow to a specific dataset and day, then keep only relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a29db",
   "metadata": {
    "tags": [
     "parameters",
     "test"
    ]
   },
   "outputs": [],
   "source": [
    "# Narrow to a specific dataset and day, then keep only relevant columns\n",
    "strain_index = 0\n",
    "dataset_name = dataset_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c5a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_mask = datasets[dataset_col] == dataset_name\n",
    "day_mask = datasets[day_col] == dataset_day_dict[dataset_name]\n",
    "\n",
    "data = datasets.loc[(name_mask) & (day_mask)].reset_index()\n",
    "\n",
    "# Somtimes there are multiple strains - so multiple rows per day\n",
    "strains = data[strain_col].unique()\n",
    "if len(strains) > 1:\n",
    "   data = data.loc[data[strain_col] == strains[strain_index]].reset_index()\n",
    "\n",
    "strains_t = data[strain_col].unique()\n",
    "assert(len(strains_t) == 1)\n",
    "strain = strains_t[0]\n",
    "\n",
    "# Sometimes there are multiple geo_accession numbers, like in GSE48018.SDY1276, average the IMMAGE, since all else is the same\n",
    "accessions = data[\"geo_accession\"].unique()\n",
    "if len(accessions) > 1:\n",
    "   print(f\"*** Multiple accession detected! Collapsing by averaging on IMMAGE value ***\\n\")\n",
    "   data =  data.groupby(uid_col, as_index=False).agg({immage_col: 'mean', **{col: 'first' for col in data.columns if col not in [uid_col, immage_col]}})\n",
    "\n",
    "# Take relevant columns only\n",
    "data = data[[immage_col, response_col, age_col]]\n",
    "\n",
    "print(f\"Working with dataset {dataset_name}\")\n",
    "print(f\"Working with strain {strain}\")\n",
    "print(f\"Total subjects in study: N={data.shape[0]}\")\n",
    "print(f\"available strains: {strains}\")\n",
    "\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2cd56a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907d1095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a boolean map of sub and super threshold values\n",
    "low_response_thr = data[[response_col]].quantile(q=0.3).item()\n",
    "\n",
    "# Generate labels\n",
    "# Note that we define y=1 for all responses < 30th percentile (and not <=)\n",
    "# Also note that we defined y=1 as *non* responders, since later on that's what we'll care most about detecting\n",
    "\n",
    "data['y'] = data[response_col].apply(lambda x: 1 if x < low_response_thr else 0)\n",
    "\n",
    "# Add a text label for plot legends\n",
    "data['Label text'] = data['y'].apply(lambda x: 'Responders' if x == 0 else 'Non-Responders')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bebcc4",
   "metadata": {},
   "source": [
    "##### Plot IMMAGE, response, and age values to look at the dynamic range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90bb8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot IMMAGE, response, and age values to look at the dynamic range\n",
    "from scipy.stats import probplot\n",
    "fig, axs = plt.subplots(2, 3, figsize=(18, 6))  # Create a figure with two subplots side by side\n",
    "\n",
    "sns.histplot(data=data, x=immage_col, bins=50, ax=axs[0, 0])\n",
    "sns.boxplot(data=data, x=immage_col, ax=axs[1, 0], fill=False)\n",
    "# axs[0].set_title('Box Plot')\n",
    "axs[0, 0].set_title(f' {immage_col}')\n",
    "\n",
    "sns.histplot(data=data, x=response_col, bins=50, ax=axs[0, 1])\n",
    "sns.boxplot(data=data, x=response_col, ax=axs[1, 1], fill=False)\n",
    "# axs[1].set_title('Box Plot')\n",
    "axs[0, 1].set_title(f' {response_col}')\n",
    "\n",
    "sns.histplot(data=data, x=age_col, bins=50, ax=axs[0, 2])\n",
    "sns.boxplot(data=data, x=age_col, ax=axs[1, 2], fill=False)\n",
    "# axs[1].set_title('Box Plot')\n",
    "axs[0, 2].set_title(f' {age_col}')\n",
    "\n",
    "plt.tight_layout(pad=3.0)  # Adjust the layout so everything fits without overlap\n",
    "fig.suptitle(f'Values Distribution in {dataset_name}, strain: {strain}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ce3943",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "##### Is there a trend like we expect? (High IMMAGE ⇒ low response)\n",
    "#### Also show the distributions of IMMAGE values for responders & non-responders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f4b533",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Sort the data by \"IMMAGE\" column\n",
    "sorted_data = data.sort_values(by=\"IMMAGE\")\n",
    "\n",
    "# Create a figure and a grid of subplots (1 row, 2 columns)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot the scatterplot on the first subplot\n",
    "sns.scatterplot(data=sorted_data, x=\"IMMAGE\", y=\"Response\", hue=\"Label text\", palette='Set1', ax=axes[0])\n",
    "axes[0].set_title(f'Vaccine response vs IMMAGE\\n({dataset_name}, {strain})')\n",
    "\n",
    "# Plot histograms on the second subplot\n",
    "sns.histplot(data=data[data[\"y\"] == 0], x=\"IMMAGE\", ax=axes[1], color=\"blue\", alpha=0.5, label=\"Responders\", bins=20)\n",
    "sns.histplot(data=data[data[\"y\"] == 1], x=\"IMMAGE\", ax=axes[1], color=\"orange\", alpha=0.5, label=\"Non-responders\", bins=20)\n",
    "axes[1].set_title(\"Histograms of IMMAGE values\")\n",
    "axes[1].legend()\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58658bc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%script true\n",
    "# Plot the response value against sorted IMMAGE, with markers signifying labels\n",
    "sorted_data = data.sort_values(by=\"IMMAGE\")\n",
    "sns.scatterplot(data=sorted_data, x=\"IMMAGE\", y=\"Response\", hue=\"Label text\", palette='Set1')\n",
    "plt.title(f'Vaccine response vs IMMAGE\\n({dataset_name}, {strain})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c1fbf0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Running a t-test\n",
    "low_group = data.loc[data[response_col]  < low_response_thr, immage_col]\n",
    "high_group = data.loc[data[response_col]  >= low_response_thr, immage_col]\n",
    "# print(f\"low group N={low_group.shape[0]}, high group N={high_group.shape[0]}\")\n",
    "\n",
    "ttest = ttest_ind(low_group, high_group)\n",
    "# print(f\"pvalue: {ttest.pvalue}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e66031c",
   "metadata": {},
   "source": [
    "##### Classifying with logistic regression - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c390097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying with logistic regression - cross validation\n",
    "log_regress_immage = LogisticRegression()\n",
    "log_regress_immage_age = LogisticRegression()\n",
    "regression_result = cross_validate(log_regress_immage, data[[immage_col]],  data[\"y\"])\n",
    "print(f\"Mean classification accuracy (logistic regression): {regression_result['test_score'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afd39a3",
   "metadata": {},
   "source": [
    "##### Classifying with logistic regression - fitting the entire dataset, and checking the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded4bd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying with logistic regression - fit on the entire dataset\n",
    "from math import log\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# X_train, X_test, labels_train, labels_test = train_test_split(data[[immage_col]], data[\"y\"],\n",
    "                                                              # test_size=0.2, random_state=42)\n",
    "# log_regress_immage.score(X_test, labels_test)\n",
    "\n",
    "def get_threshold_from_probability(prob, intercept, slope):\n",
    "  return -1 * (log(1/prob - 1) + intercept)/slope\n",
    "\n",
    "# Train a classidier based on immage and on age for comparison\n",
    "log_regress_immage.fit(data[[immage_col]],  data[\"y\"])\n",
    "log_regress_age.fit(data[[age_col]],  data[\"y\"])\n",
    "intercept = log_regress_immage.intercept_[0]\n",
    "slope = log_regress_immage.coef_[0][0]\n",
    "\n",
    "# Calculate the cutoff value\n",
    "# print(f' intercept: {intercept}, slope: {slope}')\n",
    "cutoff = get_threshold_from_probability(0.5, intercept=intercept, slope=slope) # 0.5 is the default threshold\n",
    "\n",
    "print(f\"IMMAGE cutoff value is: {cutoff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b1edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script true\n",
    "# Plot the logistic regression decision function\n",
    "from scipy.special import expit\n",
    "dft = pd.DataFrame()\n",
    "dft[\"x\"] = np.linspace(-1, 1, 500)\n",
    "dft[\"y\"] = intercept + dft.x * slope\n",
    "dft[\"y2\"] = expit(dft.x)\n",
    "dft[\"y3\"] = expit(dft.y)\n",
    "sns.lineplot(data=dft, x=\"x\", y=\"y2\")\n",
    "sns.lineplot(data=dft, x=\"x\", y=\"y3\")\n",
    "plt.title(f'expit and expit(a*X + b)\\n({dataset_name}, {strain})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29144fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot IMMAGE values and the cutoff\n",
    "sns.scatterplot(data=data.sort_values(immage_col, ignore_index=True).reset_index(), x=\"index\", y=immage_col, hue=\"Label text\")\n",
    "# commented out since cutoff is much higher and messes with the plot\n",
    "plt.axhline(y=cutoff)\n",
    "plt.title(f'sorted IMMAGE vs Index\\n({dataset_name}, {strain})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397c82bd",
   "metadata": {},
   "source": [
    "##### Logistic regreesion preforms badly, but maybe it still assigns probabilities in a way that makes sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa733308",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = pd.DataFrame(log_regress_immage.predict_proba(data[[immage_col]]))\n",
    "data[\"p_non_responder\"] = proba[1]\n",
    "\n",
    "sns.scatterplot(data=data, x=\"IMMAGE\", y=\"p_non_responder\", hue=\"Label text\", palette='Set1')\n",
    "plt.title(f'logistic regression probabilities vs IMMAGE\\n({dataset_name}, {strain})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb49ebc4",
   "metadata": {},
   "source": [
    "That's a good sign that the regressor picked up on an underlying dynamic in the direction that we were expecting.\n",
    "\n",
    " Since this is the case, maybe an ROC curve where we shift the decision threshold based on probability will still work. (The default for log. reg. is to put the decision boundary at p=0.5)\n",
    "\n",
    " The focus here is to find a threshold for classifying *non-repsponders* which maximizes the proportion of non-responders in the predicted group, not caring about predicting responders for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4cf4df",
   "metadata": {},
   "source": [
    "##### Use a logistic regression's probabilties to look for a threshold based on above-threshold non-responder rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fd1581",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_auc_score, roc_curve\n",
    "from math import log\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(data[\"y\"], data[\"p_non_responder\"])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Identifying the optimal threshold (using Youden’s Index)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "prob_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# Calculate the cutoff value\n",
    "immage_threshold = get_threshold_from_probability(prob_threshold, intercept=intercept, slope=slope)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 6))  # Creates a figure with two side-by-side subplots\n",
    "\n",
    "# Plot ROC curve on the first subplot\n",
    "axs[0].plot(fpr, tpr, label=f'ROC curve (area = {roc_auc : 0.2f})')\n",
    "axs[0].plot([0, 1], [0, 1], 'k--')  # Random chance line\n",
    "axs[0].plot(fpr[optimal_idx], tpr[optimal_idx], marker='o', markersize=5, color=\"red\")\n",
    "axs[0].set_xlim([0.0, 1.0])\n",
    "axs[0].set_ylim([0.0, 1.05])\n",
    "axs[0].set_xlabel('False Positive Rate')\n",
    "axs[0].set_ylabel('True Positive Rate')\n",
    "axs[0].set_title('ROC curve')\n",
    "axs[0].legend(loc=\"lower right\")\n",
    "\n",
    "# Plot sorted IMMAGE values vs Index on the second subplot\n",
    "sorted_data = data.sort_values(immage_col, ignore_index=True).reset_index()\n",
    "sns.scatterplot(ax=axs[1], data=sorted_data, x=\"index\", y=immage_col, hue=\"Label text\")\n",
    "axs[1].axhline(y=immage_threshold, color='black', linestyle='--')\n",
    "axs[1].set_title(f'Sorted IMMAGE vs Index')\n",
    "\n",
    "fig.suptitle(f'Probability-based threshold with ROC\\n({dataset_name}, {strain})')\n",
    "plt.tight_layout()  # Adjusts subplot params so that subplots fit into the figure area.\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Calculate the actual rate of non-responders:for i in threshold_list:\n",
    "# Global measures (entire dataset)\n",
    "optimal_pred = data[\"p_non_responder\"].apply(lambda x: 1 if x >= prob_threshold else 0)\n",
    "test_accuracy = accuracy_score(data[\"y\"], optimal_pred)\n",
    "\n",
    "# Performance above the threshold\n",
    "y_over_thr = data.loc[data[\"p_non_responder\"] >= prob_threshold, [\"y\"]]\n",
    "non_response_rate_over_thr = y_over_thr.mean().y\n",
    "y_under_thr = data.loc[data[\"p_non_responder\"] < prob_threshold, [\"y\"]]\n",
    "non_response_rate_under_thr = y_under_thr.mean().y\n",
    "print(f\"Optimal threshold: {immage_threshold : 0.2f} (IMMAGE value), Non-responder rate: over threshold: {non_response_rate_over_thr : 0.2f}, under threshold: {non_response_rate_under_thr : 0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f3861f",
   "metadata": {},
   "source": [
    "##### An alternative is to try hard IMMAGE-based thresholds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6518f81c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Manually create threshold values. Only take y=1 (non-responders) as thresholds.\n",
    "sorted_values = pd.DataFrame(pd.unique(data.loc[data[\"y\"] == 1, immage_col])).sort_values(by=0)\n",
    "thresholds = sorted_values[0]\n",
    "roc_points = []\n",
    "\n",
    "for t in thresholds:\n",
    "    # Binary predictions based on the current threshold\n",
    "    y_pred = (data[immage_col] >= t).astype(int)\n",
    "\n",
    "    # Calculate TPR and FPR for the current set of binary predictions.\n",
    "    # When roc_curve is given a binary array instead of probabilities, it calculates the fpr and tpr for the single threshold that they represent\n",
    "    fpr, tpr, _ = roc_curve(data[\"y\"], y_pred)\n",
    "    roc_points.append((fpr[1], tpr[1]))  # Assuming single threshold; fpr and tpr have two elements\n",
    "\n",
    "\n",
    "# Separate FPR and TPR values for plotting\n",
    "fprs, tprs = zip(*roc_points)\n",
    "fpr = pd.DataFrame(fprs).values\n",
    "tpr = pd.DataFrame(tprs).values\n",
    "\n",
    "# Identifying the optimal threshold (example using Youden’s Index)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "immage_threshold = thresholds[optimal_idx]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 6))  # Creates a figure with two side-by-side subplots\n",
    "\n",
    "# Plot ROC curve on the first subplot\n",
    "axs[0].plot(fpr, tpr, label=f'ROC curve (area = {roc_auc : 0.2f})')\n",
    "axs[0].plot([0, 1], [0, 1], 'k--')  # Random chance line\n",
    "axs[0].plot(fpr[optimal_idx], tpr[optimal_idx], marker='o', markersize=5, color=\"red\")\n",
    "axs[0].set_xlim([0.0, 1.0])\n",
    "axs[0].set_ylim([0.0, 1.05])\n",
    "axs[0].set_xlabel('False Positive Rate')\n",
    "axs[0].set_ylabel('True Positive Rate')\n",
    "axs[0].set_title('ROC curve')\n",
    "axs[0].legend(loc=\"lower right\")\n",
    "\n",
    "# Plot sorted IMMAGE values vs Index on the second subplot\n",
    "sns.scatterplot(data=data.sort_values(immage_col, ignore_index=True).reset_index(), x=\"index\", y=immage_col, hue=\"Label text\")\n",
    "axs[1].axhline(y=immage_threshold, color='black', linestyle='--')\n",
    "axs[1].set_title(f'Sorted IMMAGE vs Index')\n",
    "\n",
    "fig.suptitle(f'\"Hard\" IMMAGE-based threshold with ROC\\n({dataset_name}, {strain})')\n",
    "plt.tight_layout()  # Adjusts subplot params so that subplots fit into the figure area.\n",
    "plt.show()\n",
    "\n",
    "# Calculate the actual rate of non-responders:for i in threshold_list:\n",
    "# Global measures (entire dataset)\n",
    "optimal_pred = data[immage_col].apply(lambda x: 1 if x >= immage_threshold else 0)\n",
    "test_accuracy = accuracy_score(data[\"y\"], optimal_pred)\n",
    "\n",
    "# Performance above the threshold\n",
    "y_over_thr = data.loc[data[immage_col] >= immage_threshold, [\"y\"]]\n",
    "non_response_rate_over_thr = y_over_thr.mean().y\n",
    "y_under_thr = data.loc[data[immage_col] < immage_threshold, [\"y\"]]\n",
    "non_response_rate_under_thr = y_under_thr.mean().y\n",
    "print(f\"Optimal threshold: {immage_threshold : 0.2f} (IMMAGE value), Non-responder rate: over threshold: {non_response_rate_over_thr : 0.2f}, under threshold: {non_response_rate_under_thr : 0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72fc6fe",
   "metadata": {},
   "source": [
    "##### Sliding window instead of bins, plotting non-reponder rate vs window start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209b9a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_windows_and_rates(data, immage_col, num_units, num_units_per_window):\n",
    "    window_starts = np.linspace(start=data[immage_col].min(), stop=data[immage_col].max(), num=num_units)\n",
    "    window_size = (data[immage_col].max() - data[immage_col].min()) / num_units * num_units_per_window\n",
    "    windows = pd.DataFrame({\"start\": window_starts[:-num_units_per_window], \"end\": window_starts[num_units_per_window:]})\n",
    "    rates = []\n",
    "\n",
    "    for i, start, end in windows.itertuples():\n",
    "        over = data[immage_col] >= windows[\"start\"][i]\n",
    "        under = data[immage_col] < windows[\"end\"][i]\n",
    "        rates.append(data.loc[(over & under), \"y\"].mean())\n",
    "\n",
    "    rates = pd.Series(rates).fillna(0)\n",
    "    windows[\"rate\"] = rates\n",
    "    threshold_idx = rates.argmax()\n",
    "\n",
    "    return windows, window_size\n",
    "\n",
    "# Create subplots\n",
    "num_units = 100\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Iterate over different values of num_units_per_window\n",
    "for i, num_units_per_window in enumerate([10, 15, 20]):\n",
    "    windows, window_size = generate_windows_and_rates(data, immage_col, num_units, num_units_per_window)\n",
    "    sns.lineplot(data=windows, x=\"start\", y=\"rate\", ax=axs[i])\n",
    "    axs[i].axhline(y=0.5, color='black', linestyle='--')\n",
    "    axs[i].set_title(f'Window size: {window_size:.2f} IMMAGE units\\n{num_units_per_window/num_units*100:.2f}% of IMMAGE range')\n",
    "    axs[i].set_xlabel('Start')\n",
    "    axs[i].set_ylabel('Rate')\n",
    "\n",
    "# Add a common title\n",
    "fig.suptitle(f'Sliding window performance\\nrate of non-responders vs IMMAGE\\n({dataset_name}, {strain})')\n",
    "plt.subplots_adjust(top=0.75)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}