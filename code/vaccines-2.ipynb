{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e4580",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from jupyter_client import find_connection_file\n",
    "connection_file = find_connection_file()\n",
    "print(connection_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6634aaf7",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "#Plotting related\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='notebook'\n",
    "\n",
    "# Scikit-learn related imports\n",
    "import pyarrow\n",
    "import pandas as pd\n",
    "pd.options.mode.copy_on_write = True\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import randint, ttest_ind\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5f855b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "dataset_col = \"Dataset\"\n",
    "uid_col = \"uid\"\n",
    "age_col = \"Age\"\n",
    "day_col = \"Day\"\n",
    "response_col = \"Response\"\n",
    "immage_col = \"IMMAGE\"\n",
    "strain_col = 'Strain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8416b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data and drop missing values\n",
    "df = pd.read_csv(\"../data/all_vaccines.csv\")\n",
    "df.dropna(inplace=True, subset=[immage_col, dataset_col, day_col, response_col])\n",
    "\n",
    "dataset_names = df.Dataset.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9211188b",
   "metadata": {},
   "source": [
    "##### Plot distribution of studies' N values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d83675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of N values\n",
    "N_vals = df[[dataset_col, uid_col]].groupby(dataset_col, as_index=False)[uid_col].nunique()\n",
    "N_vals = N_vals.rename(columns={uid_col: \"N\"})\n",
    "sns.histplot(N_vals.N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fc434f",
   "metadata": {},
   "source": [
    "##### Narrow to large datasets only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d3cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrow N_v to large datasets only\n",
    "N_vals = N_vals.loc[N_vals[\"N\"]> 70]\n",
    "datasets = df.loc[df[\"Dataset\"].isin(N_vals[\"Dataset\"])]\n",
    "dataset_names = datasets[\"Dataset\"].unique()\n",
    "N_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da46e9b4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Examine available days per dataset\n",
    "days = datasets[[dataset_col, uid_col, day_col]].groupby(dataset_col, as_index=False)[day_col].unique()\n",
    "t = pd.Series(days.loc[[True, False, False, False], \"Day\"])\n",
    "# with pd.option_context('display.max_colwidth', None):\n",
    "#    for index, row in days.iterrows():\n",
    "#     print(f\"Dataset: {row['Dataset']}\\nDays: {row['Day']}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d6aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect day info from papers here\n",
    "dataset_day_dict = {}\n",
    "\n",
    "dataset_day_dict[\"GSE41080.SDY212\"] = \"HAI.D28\"\n",
    "dataset_day_dict[\"GSE48018.SDY1276\"] = \"nAb.D28\"\n",
    "dataset_day_dict[\"GSE48023.SDY1276\"] = \"nAb.D28\"\n",
    "dataset_day_dict[\"SDY67\"] = \"nAb.D28\"\n",
    "# dataset_day_dict[dataset_names[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b45ca3",
   "metadata": {},
   "source": [
    "##### Narrow to a specific dataset and day, then keep only relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c799c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrow to a specific dataset and day, then keep only relevant columns\n",
    "strain_index = 0\n",
    "dataset_name = dataset_names[0]\n",
    "name_mask = datasets[dataset_col] == dataset_name\n",
    "day_mask = datasets[day_col] == dataset_day_dict[dataset_name]\n",
    "\n",
    "data = datasets.loc[(name_mask) & (day_mask)].reset_index()\n",
    "\n",
    "# Somtimes there are multiple strains - so multiple rows per day\n",
    "strains = data[strain_col].unique()\n",
    "if len(strains) > 1:\n",
    "   data = data.loc[data[strain_col] == strains[strain_index]].reset_index()\n",
    "\n",
    "strains_t = data[strain_col].unique()\n",
    "assert(len(strains_t) == 1)\n",
    "strain = strains_t[0]\n",
    "\n",
    "# Sometimes there are multiple geo_accession numbers, like in GSE48018.SDY1276, average the IMMAGE, since all else is the same\n",
    "accessions = data[\"geo_accession\"].unique()\n",
    "if len(accessions) > 1:\n",
    "   print(f\"*** Multiple accession detected! Collapsing by averaging on IMMAGE value ***\\n\")\n",
    "   data =  data.groupby(uid_col, as_index=False).agg({immage_col: 'mean', **{col: 'first' for col in data.columns if col not in [uid_col, immage_col]}})\n",
    "\n",
    "# Take relevant columns only\n",
    "data = data[[immage_col, response_col, age_col]]\n",
    "\n",
    "print(f\"Working with dataset {dataset_name}\")\n",
    "print(f\"Working with strain {strain}\")\n",
    "print(f\"Total subjects in study: N={data.shape[0]}\")\n",
    "print(f\"available strains: {strains}\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc357866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a boolean map of sub and super threshold values\n",
    "low_response_thr = data[[response_col]].quantile(q=0.3).item()\n",
    "\n",
    "# Generate labels\n",
    "# Note that we define y=1 for all responses < 30th percentile (and not <=)\n",
    "# Also note that we defined y=1 as *non* responders, since later on that's what we'll care most about detecting\n",
    "data.loc[data[response_col] < low_response_thr, 'y'] = 1\n",
    "data.loc[data[response_col] >= low_response_thr, 'y'] = 0\n",
    "data.y = data.y.astype(int)\n",
    "\n",
    "# Add a text label for plot legends\n",
    "data['Label text'] = data['y'].apply(lambda x: 'Responders' if x == 0 else 'Non-Responders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d6462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sanity check for logistic regression - create a seperable dataset\n",
    "\n",
    "# mask =  pd.Series(data['y'] == 1)\n",
    "# counts = mask.value_counts()\n",
    "\n",
    "# data.loc[~mask, immage_col] = np.random.uniform(low=0, high=0.4, size=[counts[False], 1])\n",
    "# data.loc[mask, immage_col] = np.random.uniform(high=1, low=0.6, size=[counts[True], 1])\n",
    "# # data = pd.concat([data, data[data[\"Labels\"] == False].tail(3)], ignore_index=True)\n",
    "# dataset_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add05a71",
   "metadata": {},
   "source": [
    "##### Plot IMMAGE, response, and age values to look at the dynamic range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f3fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot IMMAGE, response, and age values to look at the dynamic range\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))  # Adjust figsize as needed\n",
    "pd.concat\n",
    "sns.histplot(data=data, x=immage_col, bins=50, ax=axs[0])\n",
    "axs[0].set_title(f' {immage_col}')\n",
    "axs[0].set_label(f' {immage_col}')\n",
    "\n",
    "sns.histplot(data=data, x=response_col, bins=50, ax=axs[1])\n",
    "axs[1].set_title(f' {response_col}')\n",
    "\n",
    "sns.histplot(data=data, x=age_col, bins=50, ax=axs[2])\n",
    "axs[2].set_title(f' {age_col}')\n",
    "\n",
    "fig.suptitle(f'Values Distribution in {dataset_name}, strain: {strain}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2459659a",
   "metadata": {},
   "source": [
    "##### Is there a trend like we expect? (High IMMAGE â‡’ low response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c74958",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Plot the response value against sorted IMMAGE, with markers signifying labels\n",
    "sorted_data = data.sort_values(by=\"IMMAGE\")\n",
    "sns.scatterplot(data=sorted_data, x=\"IMMAGE\", y=\"Response\", hue=\"Label text\", palette='Set1')\n",
    "plt.title(f'Vaccine response vs IMMAGE\\n({dataset_name}, {strain})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18629fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### We can already see that we won't be able to properly separate responders from non-responders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9622587",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Running a t-test\n",
    "low_group = data.loc[data[response_col]  < low_response_thr, immage_col]\n",
    "high_group = data.loc[data[response_col]  >= low_response_thr, immage_col]\n",
    "# print(f\"low group N={low_group.shape[0]}, high group N={high_group.shape[0]}\")\n",
    "\n",
    "ttest = ttest_ind(low_group, high_group)\n",
    "# print(f\"pvalue: {ttest.pvalue}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbfdcbe",
   "metadata": {},
   "source": [
    "##### Classifying with logistic regression - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc20e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying with logistic regression - cross validation\n",
    "log_regress = LogisticRegression()\n",
    "regression_result = cross_validate(log_regress, data[[immage_col]],  data[\"y\"])\n",
    "print(f\"Mean classification accuracy (logistic regression): {regression_result['test_score'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc210e61",
   "metadata": {},
   "source": [
    "##### Classifying with logistic regression - fitting the entire dataset, and checcking the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff1ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying with logistic regression - fit on the entire dataset\n",
    "from math import log\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# X_train, X_test, labels_train, labels_test = train_test_split(data[[immage_col]], data[\"y\"],\n",
    "                                                              # test_size=0.2, random_state=42)\n",
    "# log_regress.score(X_test, labels_test)\n",
    "\n",
    "def get_threshold_from_probability(prob, intercept, slope):\n",
    "  return -1 * (log(1/prob - 1) + intercept)/slope\n",
    "\n",
    "log_regress.fit(data[[immage_col]],  data[\"y\"])\n",
    "intercept = log_regress.intercept_[0]\n",
    "slope = log_regress.coef_[0][0]\n",
    "\n",
    "# Calculate the cutoff value\n",
    "# print(f' intercept: {intercept}, slope: {slope}')\n",
    "cutoff = get_threshold_from_probability(0.5, intercept=intercept, slope=slope) # 0.5 is the default threshold\n",
    "\n",
    "print(f\"IMMAGE cutoff value is: {cutoff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the logistic regression decision function\n",
    "from scipy.special import expit\n",
    "dft = pd.DataFrame()\n",
    "dft[\"x\"] = np.linspace(-1, 1, 500)\n",
    "dft[\"y\"] = intercept + dft.x * slope\n",
    "dft[\"y2\"] = expit(dft.x)\n",
    "dft[\"y3\"] = expit(dft.y)\n",
    "# sns.lineplot(data=dft, x=\"x\", y=\"y2\")\n",
    "# sns.lineplot(data=dft, x=\"x\", y=\"y3\")\n",
    "# plt.title(f'expit and expit(a*X + b)\\n({dataset_name}, {strain})')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff8f742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot IMMAGE values and the cutoff\n",
    "sns.scatterplot(data=data.sort_values(immage_col, ignore_index=True).reset_index(), x=\"index\", y=immage_col, hue=\"Label text\")\n",
    "# commented out since cutoff is much higher and messes with the plot\n",
    "plt.axhline(y=cutoff)\n",
    "plt.title(f'sorted IMMAGE vs Index\\n({dataset_name}, {strain})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2d5178",
   "metadata": {},
   "source": [
    "##### Logistic regreesion preforms badly, but maybe it still assigns probabilities in a way that makes sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad929675",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = pd.DataFrame(log_regress.predict_proba(data[[\"IMMAGE\"]]))\n",
    "proba\n",
    "data[\"p_non_responder\"] = proba[1]\n",
    "# data[\"p_non_responder\"].hist()\n",
    "# data.plot.scatter(immage_col, \"p_non_responder\")\n",
    "\n",
    "sns.scatterplot(data=data, x=\"IMMAGE\", y=\"p_non_responder\", hue=\"Label text\", palette='Set1')\n",
    "plt.title(f'logistic regression probabilities vs IMMAGE\\n({dataset_name}, {strain})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32062b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### So we see that higher IMMAGE are associated with a higher probability of *not* responding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5516c963",
   "metadata": {},
   "source": [
    "That's a good sign that the regressor picked up on an underlying dynamic in the direction that we were expecting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d06e4a0",
   "metadata": {},
   "source": [
    "##### Since this is the case, maybe an ROC curve where we shift the decision threshold based on probability will still work. (The default for log. reg. is to put the decision boundary at p=0.5)\n",
    "\n",
    "##### The focus here is to find a threshold for classifying *non-repsponders* which maximizes the proportion of non-responders in the predicted group, not caring about predicting responders for now.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73f1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_auc_score, roc_curve\n",
    "from math import log\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(data[\"y\"], data[\"p_non_responder\"])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Identifying the optimal threshold (example using Youdenâ€™s Index)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "prob_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# print(f'intercept: {intercept}, slope: {slope}')\n",
    "# Calculate the cutoff value\n",
    "immage_threshold = get_threshold_from_probability(prob_threshold, intercept=intercept, slope=slope)\n",
    "print(f\"optimal threshold: {immage_threshold : 0.2f} (IMMAGE value)\")\n",
    "\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc : 0.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Random chance line\n",
    "plt.plot(fpr[optimal_idx], tpr[optimal_idx], marker='o', markersize=5, color=\"red\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot IMMAGE values and the cutoff\n",
    "sns.scatterplot(data=data.sort_values(immage_col, ignore_index=True).reset_index(), x=\"index\", y=immage_col, hue=\"Label text\")\n",
    "plt.axhline(y=immage_threshold)\n",
    "plt.title(f'sorted IMMAGE vs Index\\n({dataset_name}, {strain})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294829ac",
   "metadata": {},
   "source": [
    "An alternative is to try hard IMMAGE-based thresholds:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2d5f42",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Manually create threshold values. Only take y=1 (non-responders) as thresholds.\n",
    "sorted_values = pd.DataFrame(pd.unique(data.loc[data[\"y\"] == 1, immage_col])).sort_values(by=0)\n",
    "thresholds = sorted_values[0]\n",
    "roc_points = []\n",
    "\n",
    "for t in thresholds:\n",
    "    # Binary predictions based on the current threshold\n",
    "    y_pred = (data[immage_col] >= t).astype(int)\n",
    "\n",
    "    # Calculate TPR and FPR for the current set of binary predictions.\n",
    "    # When roc_curve is given a binary array instead of probabilities, it calculates the fpr and tpr for the single threshold that they represent\n",
    "    fpr, tpr, _ = roc_curve(data[\"y\"], y_pred)\n",
    "    roc_points.append((fpr[1], tpr[1]))  # Assuming single threshold; fpr and tpr have two elements\n",
    "\n",
    "\n",
    "# Separate FPR and TPR values for plotting\n",
    "fprs, tprs = zip(*roc_points)\n",
    "fpr = pd.DataFrame(fprs).values\n",
    "tpr = pd.DataFrame(tprs).values\n",
    "\n",
    "# Identifying the optimal threshold (example using Youdenâ€™s Index)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "immage_threshold = thresholds[optimal_idx]\n",
    "print(f\"optimal threshold: {immage_threshold : 0.2f} (IMMAGE value)\")\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Chance Level')\n",
    "plt.plot(fpr[optimal_idx], tpr[optimal_idx], marker='o', markersize=5, color=\"red\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Hard Thresholds on IMMAGE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot IMMAGE values and the cutoff\n",
    "sns.scatterplot(data=data.sort_values(immage_col, ignore_index=True).reset_index(), x=\"index\", y=immage_col, hue=\"Label text\")\n",
    "plt.axhline(y=immage_threshold)\n",
    "plt.title(f'sorted IMMAGE vs Index\\n({dataset_name}, {strain})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad14b09e",
   "metadata": {},
   "source": [
    "##### Which give a different threshold with the same AUC score\n",
    "\n",
    "##### Another option it to bin IMMAGE values and look for where the rate of non-responders changes\n",
    "##### TODO: We can make this more elaborate by using different # of bins and making and ROC from the maximum rate we find in each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7eb82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Bin the data based on IMMAGE, look for a change in non-responder rate (proportion)\n",
    "\n",
    "n_bins = 6\n",
    "B = pd.cut(data[\"IMMAGE\"], bins=n_bins, labels=range(n_bins))\n",
    "data[\"bin\"] = B.values.astype(int)\n",
    "\n",
    "grouped = data.groupby(\"bin\", as_index=False)['y'].mean()\n",
    "\n",
    "t = pd.DataFrame({\"bin\" : grouped[\"bin\"], \"NR rate\": grouped[\"y\"]})\n",
    "print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}