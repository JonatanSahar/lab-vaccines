{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ed2a6e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from jupyter_client import find_connection_file\n",
    "connection_file = find_connection_file()\n",
    "print(connection_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab6abe3",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "#Plotting related\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='notebook'\n",
    "\n",
    "# Scikit-learn related imports\n",
    "import pyarrow\n",
    "import pandas as pd\n",
    "pd.options.mode.copy_on_write = True\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import randint, ttest_ind\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00161a30",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "dataset_col = \"Dataset\"\n",
    "uid_col = \"uid\"\n",
    "age_col = \"Age\"\n",
    "day_col = \"Day\"\n",
    "response_col = \"Response\"\n",
    "immage_col = \"IMMAGE\"\n",
    "strain_col = 'Strain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08bd8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data and drop missing values\n",
    "df = pd.read_csv(\"../data/all_vaccines.csv\")\n",
    "df.dropna(inplace=True, subset=[immage_col, dataset_col, day_col, response_col])\n",
    "\n",
    "dataset_names = df.Dataset.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f379816f",
   "metadata": {},
   "source": [
    "##### Plot distribution of studies' N values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb9c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of N values\n",
    "N_vals = df[[dataset_col, uid_col]].groupby(dataset_col, as_index=False)[uid_col].nunique()\n",
    "N_vals = N_vals.rename(columns={uid_col: \"N\"})\n",
    "sns.histplot(N_vals.N)\n",
    "plt.title(\"N values across studies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dbbc93",
   "metadata": {},
   "source": [
    "##### Narrow to large datasets only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f6f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrow N_v to large datasets only\n",
    "N_vals = N_vals.loc[N_vals[\"N\"]> 70]\n",
    "datasets = df.loc[df[\"Dataset\"].isin(N_vals[\"Dataset\"])]\n",
    "dataset_names = datasets[\"Dataset\"].unique()\n",
    "N_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e05d54",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Examine available days per dataset\n",
    "days = datasets[[dataset_col, uid_col, day_col]].groupby(dataset_col, as_index=False)[day_col].unique()\n",
    "t = pd.Series(days.loc[[True, False, False, False], \"Day\"])\n",
    "# with pd.option_context('display.max_colwidth', None):\n",
    "#    for index, row in days.iterrows():\n",
    "#     print(f\"Dataset: {row['Dataset']}\\nDays: {row['Day']}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9ee157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect day info from papers here\n",
    "dataset_day_dict = {}\n",
    "\n",
    "dataset_day_dict[\"GSE41080.SDY212\"] = \"HAI.D28\"\n",
    "dataset_day_dict[\"GSE48018.SDY1276\"] = \"nAb.D28\"\n",
    "dataset_day_dict[\"GSE48023.SDY1276\"] = \"nAb.D28\"\n",
    "dataset_day_dict[\"SDY67\"] = \"nAb.D28\"\n",
    "# dataset_day_dict[dataset_names[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15607d2c",
   "metadata": {},
   "source": [
    "##### Narrow to a specific dataset and day, then keep only relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141bea1e",
   "metadata": {
    "tags": [
     "parameters",
     "test"
    ]
   },
   "outputs": [],
   "source": [
    "# Narrow to a specific dataset and day, then keep only relevant columns\n",
    "strain_index = 0\n",
    "dataset_name = dataset_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c9099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_mask = datasets[dataset_col] == dataset_name\n",
    "day_mask = datasets[day_col] == dataset_day_dict[dataset_name]\n",
    "\n",
    "data = datasets.loc[(name_mask) & (day_mask)].reset_index()\n",
    "\n",
    "# Somtimes there are multiple strains - so multiple rows per day\n",
    "strains = data[strain_col].unique()\n",
    "if len(strains) > 1:\n",
    "   data = data.loc[data[strain_col] == strains[strain_index]].reset_index()\n",
    "\n",
    "strains_t = data[strain_col].unique()\n",
    "assert(len(strains_t) == 1)\n",
    "strain = strains_t[0]\n",
    "\n",
    "# Sometimes there are multiple geo_accession numbers, like in GSE48018.SDY1276, average the IMMAGE, since all else is the same\n",
    "accessions = data[\"geo_accession\"].unique()\n",
    "if len(accessions) > 1:\n",
    "   print(f\"*** Multiple accession detected! Collapsing by averaging on IMMAGE value ***\\n\")\n",
    "   data =  data.groupby(uid_col, as_index=False).agg({immage_col: 'mean', **{col: 'first' for col in data.columns if col not in [uid_col, immage_col]}})\n",
    "\n",
    "# Take relevant columns only\n",
    "data = data[[immage_col, response_col, age_col]]\n",
    "\n",
    "print(f\"Working with dataset {dataset_name}\")\n",
    "print(f\"Working with strain {strain}\")\n",
    "print(f\"Total subjects in study: N={data.shape[0]}\")\n",
    "print(f\"available strains: {strains}\")\n",
    "\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727d421f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cea2fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a boolean map of sub and super threshold values\n",
    "low_response_thr = data[[response_col]].quantile(q=0.3).item()\n",
    "\n",
    "# Generate labels\n",
    "# Note that we define y=1 for all responses < 30th percentile (and not <=)\n",
    "# Also note that we defined y=1 as *non* responders, since later on that's what we'll care most about detecting\n",
    "\n",
    "# data.loc[data[response_col] < low_response_thr, 'y'] = 1\n",
    "# data.loc[data[response_col] >= low_response_thr, 'y'] = 0\n",
    "# data.y = data.y.astype(int)\n",
    "\n",
    "data['y'] = data[response_col].apply(lambda x: 1 if x < low_response_thr else 0)\n",
    "# Add a text label for plot legends\n",
    "data['Label text'] = data['y'].apply(lambda x: 'Responders' if x == 0 else 'Non-Responders')\n",
    "# low_response_thr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e60b33f",
   "metadata": {},
   "source": [
    "##### Plot IMMAGE, response, and age values to look at the dynamic range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b82c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot IMMAGE, response, and age values to look at the dynamic range\n",
    "from scipy.stats import probplot\n",
    "fig, axs = plt.subplots(2, 3, figsize=(18, 6))  # Create a figure with two subplots side by side\n",
    "\n",
    "sns.histplot(data=data, x=immage_col, bins=50, ax=axs[0, 0])\n",
    "sns.boxplot(data=data, x=immage_col, ax=axs[1, 0], fill=False)\n",
    "# axs[0].set_title('Box Plot')\n",
    "axs[0, 0].set_title(f' {immage_col}')\n",
    "\n",
    "sns.histplot(data=data, x=response_col, bins=50, ax=axs[0, 1])\n",
    "sns.boxplot(data=data, x=response_col, ax=axs[1, 1], fill=False)\n",
    "# axs[1].set_title('Box Plot')\n",
    "axs[0, 1].set_title(f' {response_col}')\n",
    "\n",
    "sns.histplot(data=data, x=age_col, bins=50, ax=axs[0, 2])\n",
    "sns.boxplot(data=data, x=age_col, ax=axs[1, 2], fill=False)\n",
    "# axs[1].set_title('Box Plot')\n",
    "axs[0, 2].set_title(f' {age_col}')\n",
    "\n",
    "plt.tight_layout(pad=3.0)  # Adjust the layout so everything fits without overlap\n",
    "fig.suptitle(f'Values Distribution in {dataset_name}, strain: {strain}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926c8653",
   "metadata": {},
   "source": [
    "##### Is there a trend like we expect? (High IMMAGE ⇒ low response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcb7097",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Plot the response value against sorted IMMAGE, with markers signifying labels\n",
    "sorted_data = data.sort_values(by=\"IMMAGE\")\n",
    "sns.scatterplot(data=sorted_data, x=\"IMMAGE\", y=\"Response\", hue=\"Label text\", palette='Set1')\n",
    "plt.title(f'Vaccine response vs IMMAGE\\n({dataset_name}, {strain})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29bd0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### We can already see that we won't be able to properly separate responders from non-responders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af774715",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Running a t-test\n",
    "low_group = data.loc[data[response_col]  < low_response_thr, immage_col]\n",
    "high_group = data.loc[data[response_col]  >= low_response_thr, immage_col]\n",
    "# print(f\"low group N={low_group.shape[0]}, high group N={high_group.shape[0]}\")\n",
    "\n",
    "ttest = ttest_ind(low_group, high_group)\n",
    "# print(f\"pvalue: {ttest.pvalue}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207fd83c",
   "metadata": {},
   "source": [
    "##### Classifying with logistic regression - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c056d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying with logistic regression - cross validation\n",
    "log_regress = LogisticRegression()\n",
    "regression_result = cross_validate(log_regress, data[[immage_col]],  data[\"y\"])\n",
    "print(f\"Mean classification accuracy (logistic regression): {regression_result['test_score'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5003fab1",
   "metadata": {},
   "source": [
    "##### Classifying with logistic regression - fitting the entire dataset, and checking the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c858d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying with logistic regression - fit on the entire dataset\n",
    "from math import log\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# X_train, X_test, labels_train, labels_test = train_test_split(data[[immage_col]], data[\"y\"],\n",
    "                                                              # test_size=0.2, random_state=42)\n",
    "# log_regress.score(X_test, labels_test)\n",
    "\n",
    "def get_threshold_from_probability(prob, intercept, slope):\n",
    "  return -1 * (log(1/prob - 1) + intercept)/slope\n",
    "\n",
    "log_regress.fit(data[[immage_col]],  data[\"y\"])\n",
    "intercept = log_regress.intercept_[0]\n",
    "slope = log_regress.coef_[0][0]\n",
    "\n",
    "# Calculate the cutoff value\n",
    "# print(f' intercept: {intercept}, slope: {slope}')\n",
    "cutoff = get_threshold_from_probability(0.5, intercept=intercept, slope=slope) # 0.5 is the default threshold\n",
    "\n",
    "print(f\"IMMAGE cutoff value is: {cutoff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a607494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the logistic regression decision function\n",
    "from scipy.special import expit\n",
    "dft = pd.DataFrame()\n",
    "dft[\"x\"] = np.linspace(-1, 1, 500)\n",
    "dft[\"y\"] = intercept + dft.x * slope\n",
    "dft[\"y2\"] = expit(dft.x)\n",
    "dft[\"y3\"] = expit(dft.y)\n",
    "# sns.lineplot(data=dft, x=\"x\", y=\"y2\")\n",
    "# sns.lineplot(data=dft, x=\"x\", y=\"y3\")\n",
    "# plt.title(f'expit and expit(a*X + b)\\n({dataset_name}, {strain})')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f5766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot IMMAGE values and the cutoff\n",
    "sns.scatterplot(data=data.sort_values(immage_col, ignore_index=True).reset_index(), x=\"index\", y=immage_col, hue=\"Label text\")\n",
    "# commented out since cutoff is much higher and messes with the plot\n",
    "plt.axhline(y=cutoff)\n",
    "plt.title(f'sorted IMMAGE vs Index\\n({dataset_name}, {strain})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6842d1",
   "metadata": {},
   "source": [
    "##### Logistic regreesion preforms badly, but maybe it still assigns probabilities in a way that makes sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06622672",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = pd.DataFrame(log_regress.predict_proba(data[[\"IMMAGE\"]]))\n",
    "data[\"p_non_responder\"] = proba[1]\n",
    "# data[\"p_non_responder\"].hist()\n",
    "# data.plot.scatter(immage_col, \"p_non_responder\")\n",
    "\n",
    "sns.scatterplot(data=data, x=\"IMMAGE\", y=\"p_non_responder\", hue=\"Label text\", palette='Set1')\n",
    "plt.title(f'logistic regression probabilities vs IMMAGE\\n({dataset_name}, {strain})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff9518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### So we see that higher IMMAGE are associated with a higher probability of *not* responding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc07069",
   "metadata": {},
   "source": [
    "That's a good sign that the regressor picked up on an underlying dynamic in the direction that we were expecting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbe9ba2",
   "metadata": {},
   "source": [
    "##### Since this is the case, maybe an ROC curve where we shift the decision threshold based on probability will still work. (The default for log. reg. is to put the decision boundary at p=0.5)\n",
    "\n",
    "##### The focus here is to find a threshold for classifying *non-repsponders* which maximizes the proportion of non-responders in the predicted group, not caring about predicting responders for now.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34cf9d7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_auc_score, roc_curve\n",
    "from math import log\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(data[\"y\"], data[\"p_non_responder\"])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Identifying the optimal threshold (example using Youden’s Index)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "prob_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# print(f'intercept: {intercept}, slope: {slope}')\n",
    "# Calculate the cutoff value\n",
    "immage_threshold = get_threshold_from_probability(prob_threshold, intercept=intercept, slope=slope)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 6))  # Creates a figure with two side-by-side subplots\n",
    "\n",
    "# Plot ROC curve on the first subplot\n",
    "axs[0].plot(fpr, tpr, label=f'ROC curve (area = {roc_auc : 0.2f})')\n",
    "axs[0].plot([0, 1], [0, 1], 'k--')  # Random chance line\n",
    "axs[0].plot(fpr[optimal_idx], tpr[optimal_idx], marker='o', markersize=5, color=\"red\")\n",
    "axs[0].set_xlim([0.0, 1.0])\n",
    "axs[0].set_ylim([0.0, 1.05])\n",
    "axs[0].set_xlabel('False Positive Rate')\n",
    "axs[0].set_ylabel('True Positive Rate')\n",
    "axs[0].set_title('ROC curve')\n",
    "axs[0].legend(loc=\"lower right\")\n",
    "\n",
    "# Plot sorted IMMAGE values vs Index on the second subplot\n",
    "sorted_data = data.sort_values(immage_col, ignore_index=True).reset_index()\n",
    "sns.scatterplot(ax=axs[1], data=sorted_data, x=\"index\", y=immage_col, hue=\"Label text\")\n",
    "axs[1].axhline(y=immage_threshold, color='black', linestyle='--')\n",
    "axs[1].set_title(f'Sorted IMMAGE vs Index')\n",
    "\n",
    "fig.suptitle(f'Probability-based threshold with ROC\\n({dataset_name}, {strain})')\n",
    "plt.tight_layout()  # Adjusts subplot params so that subplots fit into the figure area.\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Calculate the actual rate of non-responders:for i in threshold_list:\n",
    "# Global measures (entire dataset)\n",
    "optimal_pred = data[\"p_non_responder\"].apply(lambda x: 1 if x >= prob_threshold else 0)\n",
    "test_accuracy = accuracy_score(data[\"y\"], optimal_pred)\n",
    "\n",
    "# Performance above the threshold\n",
    "y_over_thr = data.loc[data[\"p_non_responder\"] >= prob_threshold, [\"y\"]]\n",
    "non_response_rate_over_thr = y_over_thr.mean().y\n",
    "y_under_thr = data.loc[data[\"p_non_responder\"] < prob_threshold, [\"y\"]]\n",
    "non_response_rate_under_thr = y_under_thr.mean().y\n",
    "print(f\"Optimal threshold: {immage_threshold : 0.2f} (IMMAGE value), Non-responder rate: over threshold: {non_response_rate_over_thr : 0.2f}, under threshold: {non_response_rate_under_thr : 0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ef6132",
   "metadata": {},
   "source": [
    "##### An alternative is to try hard IMMAGE-based thresholds:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70a7dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually create threshold values. Only take y=1 (non-responders) as thresholds.\n",
    "sorted_values = pd.DataFrame(pd.unique(data.loc[data[\"y\"] == 1, immage_col])).sort_values(by=0)\n",
    "thresholds = sorted_values[0]\n",
    "roc_points = []\n",
    "\n",
    "for t in thresholds:\n",
    "    # Binary predictions based on the current threshold\n",
    "    y_pred = (data[immage_col] >= t).astype(int)\n",
    "\n",
    "    # Calculate TPR and FPR for the current set of binary predictions.\n",
    "    # When roc_curve is given a binary array instead of probabilities, it calculates the fpr and tpr for the single threshold that they represent\n",
    "    fpr, tpr, _ = roc_curve(data[\"y\"], y_pred)\n",
    "    roc_points.append((fpr[1], tpr[1]))  # Assuming single threshold; fpr and tpr have two elements\n",
    "\n",
    "\n",
    "# Separate FPR and TPR values for plotting\n",
    "fprs, tprs = zip(*roc_points)\n",
    "fpr = pd.DataFrame(fprs).values\n",
    "tpr = pd.DataFrame(tprs).values\n",
    "\n",
    "# Identifying the optimal threshold (example using Youden’s Index)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "immage_threshold = thresholds[optimal_idx]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 6))  # Creates a figure with two side-by-side subplots\n",
    "\n",
    "# Plot ROC curve on the first subplot\n",
    "axs[0].plot(fpr, tpr, label=f'ROC curve (area = {roc_auc : 0.2f})')\n",
    "axs[0].plot([0, 1], [0, 1], 'k--')  # Random chance line\n",
    "axs[0].plot(fpr[optimal_idx], tpr[optimal_idx], marker='o', markersize=5, color=\"red\")\n",
    "axs[0].set_xlim([0.0, 1.0])\n",
    "axs[0].set_ylim([0.0, 1.05])\n",
    "axs[0].set_xlabel('False Positive Rate')\n",
    "axs[0].set_ylabel('True Positive Rate')\n",
    "axs[0].set_title('ROC curve')\n",
    "axs[0].legend(loc=\"lower right\")\n",
    "\n",
    "# Plot sorted IMMAGE values vs Index on the second subplot\n",
    "sns.scatterplot(data=data.sort_values(immage_col, ignore_index=True).reset_index(), x=\"index\", y=immage_col, hue=\"Label text\")\n",
    "axs[1].axhline(y=immage_threshold, color='black', linestyle='--')\n",
    "axs[1].set_title(f'Sorted IMMAGE vs Index')\n",
    "\n",
    "fig.suptitle(f'\"Hard\" IMMAGE-based threshold with ROC\\n({dataset_name}, {strain})')\n",
    "plt.tight_layout()  # Adjusts subplot params so that subplots fit into the figure area.\n",
    "plt.show()\n",
    "\n",
    "# Calculate the actual rate of non-responders:for i in threshold_list:\n",
    "# Global measures (entire dataset)\n",
    "optimal_pred = data[immage_col].apply(lambda x: 1 if x >= immage_threshold else 0)\n",
    "test_accuracy = accuracy_score(data[\"y\"], optimal_pred)\n",
    "\n",
    "# Performance above the threshold\n",
    "y_over_thr = data.loc[data[immage_col] >= immage_threshold, [\"y\"]]\n",
    "non_response_rate_over_thr = y_over_thr.mean().y\n",
    "y_under_thr = data.loc[data[immage_col] < immage_threshold, [\"y\"]]\n",
    "non_response_rate_under_thr = y_under_thr.mean().y\n",
    "print(f\"Optimal threshold: {immage_threshold : 0.2f} (IMMAGE value), Non-responder rate: over threshold: {non_response_rate_over_thr : 0.2f}, under threshold: {non_response_rate_under_thr : 0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd603ba",
   "metadata": {},
   "source": [
    "##### Another option is to directly choose the threshold that gives the highest rate of non-responders (i.e. not through optimizing on ROC). The question is how to regularize it so it won't give us only the last samples in cases where they are all positive (=non-responders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb93c3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually create threshold values. Only take y=1 (non-responders) as thresholds.\n",
    "sorted_values = pd.DataFrame(pd.unique(data.loc[data[\"y\"] == 1, immage_col])).rename(columns={0:\"threshold\"}).sort_values(by=\"threshold\").reset_index(drop=True)\n",
    "thresholds = sorted_values\n",
    "# thresholds = sorted_values[\"threshold\"]\n",
    "# rates = pd.Series(name=\"rates\")\n",
    "rates = []\n",
    "\n",
    "for i, t in thresholds.itertuples():\n",
    "    # Binary predictions based on the current threshold\n",
    "    rates.append(data.loc[data[immage_col] >= t,\"y\"].mean())\n",
    "\n",
    "rates = pd.Series(rates)\n",
    "threshold_idx = rates.argmax()\n",
    "immage_threshold = thresholds[\"threshold\"].iloc[threshold_idx]\n",
    "\n",
    "# Plot IMMAGE values and the cutoff\n",
    "sns.scatterplot(data=data.sort_values(immage_col, ignore_index=True).reset_index(), x=\"index\", y=immage_col, hue=\"Label text\")\n",
    "plt.axhline(y=immage_threshold)\n",
    "plt.title(f'Threshold based on \"highest over-threshold rate (no regularization)\"\\n({dataset_name}, {strain})\\nsorted IMMAGE vs Index')\n",
    "plt.show()\n",
    "\n",
    "# Calculate the actual rate of non-responders:for i in threshold_list:\n",
    "# Global measures (entire dataset)\n",
    "optimal_pred = data[immage_col].apply(lambda x: 1 if x >= immage_threshold else 0)\n",
    "test_accuracy = accuracy_score(data[\"y\"], optimal_pred)\n",
    "\n",
    "# Performance above the threshold\n",
    "y_over_thr = data.loc[data[immage_col] >= immage_threshold, [\"y\"]]\n",
    "non_response_rate_over_thr = y_over_thr.mean().y\n",
    "y_under_thr = data.loc[data[immage_col] < immage_threshold, [\"y\"]]\n",
    "non_response_rate_under_thr = y_under_thr.mean().y\n",
    "print(f\"Optimal threshold: {immage_threshold : 0.2f} (IMMAGE value), Non-responder rate: over threshold: {non_response_rate_over_thr : 0.2f}, under threshold: {non_response_rate_under_thr : 0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73de18c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script true\n",
    "\n",
    "##### Another option it to bin IMMAGE values and look for where the rate of non-responders changes\n",
    "##### TODO: We can make this more elaborate by using different number of bins and looking for the maximum or add regularization\n",
    "\n",
    "# Bin the data based on IMMAGE, look for a change in non-responder rate (proportion)\n",
    "\n",
    "n_bins = 6\n",
    "B = pd.cut(data[\"IMMAGE\"], bins=n_bins, labels=range(n_bins))\n",
    "data[\"bin\"] = B.values.astype(int)\n",
    "\n",
    "grouped = data.groupby(\"bin\", as_index=False)['y'].mean()\n",
    "\n",
    "t = pd.DataFrame({\"bin\" : grouped[\"bin\"], \"NR rate\": grouped[\"y\"]})\n",
    "print(t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb406ccb",
   "metadata": {},
   "source": [
    "##### Sliding window instead of bins, plotting non-reponder rate vs window start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fdd0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script true\n",
    "\n",
    "# Create the windows in advance, divide the range of IMMAGE values into U units, each window starts at a unit and is N units long. We have U - N windows.\n",
    "num_units = 100\n",
    "num_units_per_window = 15\n",
    "window_size = (data[immage_col].max() - data[immage_col].min()) / num_units * num_units_per_window\n",
    "\n",
    "window_starts = np.linspace(start=data[immage_col].min(), stop=data[immage_col].max(), num=100)\n",
    "rates = []\n",
    "\n",
    "# Now create the DataFrame\n",
    "windows=pd.DataFrame({\"start\": window_starts[:-num_units_per_window], \"end\": window_starts[num_units_per_window:]})\n",
    "\n",
    "for i, start, end in windows.itertuples() :\n",
    "    # Binary predictions based on the current threshold\n",
    "    over = data[immage_col] >= windows[\"start\"][i]\n",
    "    under = data[immage_col] < windows[\"end\"][i]\n",
    "    rates.append(data.loc[(over & under), \"y\"].mean())\n",
    "\n",
    "rates = pd.Series(rates).fillna(0)\n",
    "windows[\"rate\"] = rates\n",
    "threshold_idx = rates.argmax()\n",
    "\n",
    "# Plot IMMAGE values and the cutoff\n",
    "# immage_threshold = thresholds[\"threshold\"].iloc[threshold_idx]\n",
    "sns.lineplot(data=windows, x=\"start\", y=\"rate\")\n",
    "plt.axhline(y=0.5, color='black', linestyle='--')\n",
    "plt.title(f'Sliding window performance \\n rate of non-responders vs IMMAGE\\n({dataset_name}, {strain})')\n",
    "\n",
    "\n",
    "plt.text(-0.35, 0.75, f' Window size:\\n{window_size : 0.2f} IMMAGE units\\n{num_units_per_window/num_units*100 : 0.2f} percent of IMMAGE range', fontsize=10, ha='left', va='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af50822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_windows_and_rates(data, immage_col, num_units, num_units_per_window):\n",
    "    window_starts = np.linspace(start=data[immage_col].min(), stop=data[immage_col].max(), num=num_units)\n",
    "    window_size = (data[immage_col].max() - data[immage_col].min()) / num_units * num_units_per_window\n",
    "    windows = pd.DataFrame({\"start\": window_starts[:-num_units_per_window], \"end\": window_starts[num_units_per_window:]})\n",
    "    rates = []\n",
    "\n",
    "    for i, start, end in windows.itertuples():\n",
    "        over = data[immage_col] >= windows[\"start\"][i]\n",
    "        under = data[immage_col] < windows[\"end\"][i]\n",
    "        rates.append(data.loc[(over & under), \"y\"].mean())\n",
    "\n",
    "    rates = pd.Series(rates).fillna(0)\n",
    "    windows[\"rate\"] = rates\n",
    "    threshold_idx = rates.argmax()\n",
    "\n",
    "    return windows, window_size\n",
    "\n",
    "# Create subplots\n",
    "num_units = 100\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Iterate over different values of num_units_per_window\n",
    "for i, num_units_per_window in enumerate([10, 15, 20]):\n",
    "    windows, window_size = generate_windows_and_rates(data, immage_col, num_units, num_units_per_window)\n",
    "    sns.lineplot(data=windows, x=\"start\", y=\"rate\", ax=axs[i])\n",
    "    axs[i].axhline(y=0.5, color='black', linestyle='--')\n",
    "    axs[i].set_title(f'Window size: {window_size:.2f} IMMAGE units\\n{num_units_per_window/num_units*100:.2f}% of IMMAGE range')\n",
    "    axs[i].set_xlabel('Start')\n",
    "    axs[i].set_ylabel('Rate')\n",
    "\n",
    "# Add a common title\n",
    "fig.suptitle(f'Sliding window performance\\nrate of non-responders vs IMMAGE\\n({dataset_name}, {strain})')\n",
    "plt.subplots_adjust(top=0.75)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}