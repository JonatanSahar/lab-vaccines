{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd2192c",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "from jupyter_client import find_connection_file\n",
    "\n",
    "connection_file = find_connection_file()\n",
    "print(connection_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb8bce8",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "# Plotting related\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.tracebacklimit = 0\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# sns.set_palette([\"#3498db\", \"orange\"])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "\n",
    "# Scikit-learn related imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import randint, ttest_ind\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Jupyter-related\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "\n",
    "# Constants for this project\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954f69b2",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change the current working directory\n",
    "os.chdir(\"/home/yonatan/Documents/projects/vaccines/code\")\n",
    "\n",
    "# maybe make plotly work\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8348c0c",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "def get_data_dir():\n",
    "    # Define the starting directory\n",
    "    current_dir = os.getcwd()\n",
    "\n",
    "    # Traverse up the directory tree until we find a directory named \"data\"\n",
    "    while current_dir != \"/\":\n",
    "        if \"data\" in os.listdir(current_dir):\n",
    "            data_dir = os.path.join(current_dir, \"data\")\n",
    "            return data_dir\n",
    "        current_dir = os.path.dirname(current_dir)\n",
    "    else:\n",
    "        print(\"Directory 'data' not found in the parent directories.\")\n",
    "        raise ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beb9f4f",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "# Read in Data and drop missing values\n",
    "data_dir = get_data_dir()\n",
    "df = pd.read_csv(os.path.join(data_dir, \"../data/all_vaccines.csv\"))\n",
    "df.dropna(inplace=True, subset=[immage_col, dataset_col, day_col, response_col])\n",
    "\n",
    "datasets = df\n",
    "dataset_names = df.Dataset.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b620131",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "# #### Distribution of studies' N values\n",
    "N_vals = df[[dataset_col, uid_col]].groupby(dataset_col, as_index=False)[uid_col].nunique()\n",
    "N_vals = N_vals.rename(columns={uid_col: \"N\"})\n",
    "# sns.histplot(N_vals.N)\n",
    "# plt.title(\"N values across studies\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8925f7",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "# Narrow N_v to large datasets only\n",
    "bNarrow = False\n",
    "large_N = N_vals.loc[N_vals[\"N\"] > 70]\n",
    "if bNarrow:\n",
    "    print(\"Narrowing to large datasets only\")\n",
    "    datasets = df.loc[df[\"Dataset\"].isin(large_N[\"Dataset\"])]\n",
    "\n",
    "dataset_names = datasets[\"Dataset\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647770f",
   "metadata": {
    "papermill": {},
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# These parameters are overridden by papermill\n",
    "strain_index = 1\n",
    "dataset_name = \"GSE41080.SDY212\"\n",
    "day = \"FC.HAI\"\n",
    "day0 = \"HAI.D0\"\n",
    "dayMFC = \"HAI.MFC\"\n",
    "\n",
    "bAdjustMFC = False\n",
    "bInfluenza = True\n",
    "bDiscardSeroprotected = False\n",
    "bOlderOnly = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388ed8a8",
   "metadata": {
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "bAdjustMFC = False\n",
    "dataset_name = \"GSE59743.SDY400\"\n",
    "strain_index = 2\n",
    "day = \"FC.HAI\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739c3043",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "if bInfluenza:\n",
    "    tmp_df = pd.DataFrame(influenza_dicts)\n",
    "    datasets = df.loc[df[\"Dataset\"].isin(tmp_df[\"Dataset\"])]\n",
    "    dataset_names = datasets[\"Dataset\"].unique()\n",
    "    tmp_df['Days'] = tmp_df['Days'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)  # Convert list to string for display\n",
    "    # print(tmp_df)\n",
    "    print(\"Working with Influenza datasets only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f543b916",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Narrow to a specific datset\n",
    "name_mask = datasets[dataset_col] == dataset_name\n",
    "dataset = datasets.loc[name_mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15d429e",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate MFC for datasets which don't have it.\n",
    "# Need to normalize day0 and then.. Look at the paper\n",
    "# day_mask = dataset[day_col] == day\n",
    "# t = dataset.loc[day_mask]\n",
    "# t = dataset.groupby(uid_col)[response_col].max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484707b2",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pivot the dataset such that different days' samples appear in their own columns, witn NaN where there are missing samples\n",
    "t = dataset[[dataset_col, uid_col, age_col, immage_col, \"geo_accession\", day_col, response_col]]\n",
    "pivot_t = t.pivot_table(index=uid_col, columns=day_col, values=response_col, aggfunc='first')\n",
    "age_t = dataset[['uid', 'Age']].drop_duplicates()\n",
    "\n",
    "# Average IMMAGE values across geo_accessions (if they exist) and merge\n",
    "immage_t = t.groupby('uid')[immage_col].mean()\n",
    "tmp_t = age_t.merge(immage_t, on='uid', how='left').drop_duplicates()\n",
    "pivot_t = tmp_t.merge(pivot_t, on='uid', how='left')\n",
    "\n",
    "# Reset index to make uid a column again\n",
    "pivot_t.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Remove the name of the columns and index name\n",
    "pivot_t.columns.name = None\n",
    "pivot_t.index.name = None\n",
    "\n",
    "# TODO complete generating MFC for this dataset\n",
    "# if dataset_name == 'SDY296' or dataset_name == 'GSE48023.SDY1276':\n",
    "#     dataset = dataset.loc[(~pivot_t[day0].isna()) & (~pivot_t[\"FC.HAI\"].isna())]\n",
    "#     pivot_t[dayMFC] = pivot_t[day] / pivot_t[day0]\n",
    "\n",
    "# Currently only used by AdjustMFC branch. TODO: convert the \"regular\" to use it too\n",
    "pivot_dataset = pivot_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e66e5c",
   "metadata": {
    "lines_to_next_cell": 1,
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sometimes there are multiple geo_accession numbers, like in GSE48018.SDY1276.\n",
    "# Average the IMMAGE, since all else is the same\n",
    "def remove_duplicate_accessions(dataset, immage_col, uid_col):\n",
    "    first_uid = dataset.iloc[0][uid_col]\n",
    "    accessions = dataset[dataset[uid_col] == first_uid][\"geo_accession\"].unique()\n",
    "    if len(accessions) > 1:\n",
    "        # print(f\"Multiple accession detected, Collapsing by averaging on IMMAGE value\")\n",
    "        dataset = dataset.groupby(uid_col, as_index=False).agg({immage_col: \"mean\", **{col: \"first\" for col in dataset.columns if col not in [uid_col, immage_col]},})\n",
    "\n",
    "    accessions = dataset[dataset[uid_col] == first_uid][\"geo_accession\"].unique()\n",
    "    assert len(accessions) == 1\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca488cc",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# Use adjusted MFC (HAI) as per John Tsang\n",
    "cluster_col = day0\n",
    "if bAdjustMFC:\n",
    "    exit(1)\n",
    "    dataset = pivot_dataset[[uid_col, immage_col, age_col, day0, dayMFC]]\n",
    "    print(\"Preprocessing dataset, computing adjusted MFC (HAI)\")\n",
    "    dataset = dataset.loc[(~pivot_t[day0].isna()) & (~pivot_t[dayMFC].isna())]\n",
    "\n",
    "    mean = dataset[day0].mean()\n",
    "    std = dataset[day0].std()\n",
    "    threshold = 3 * std\n",
    "    dataset = dataset[(dataset[day0] >= mean - threshold) & (dataset[day0] <= mean + threshold)]\n",
    "\n",
    "    # Bin subjects into 2-3 bins using k-means clustering\n",
    "    kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "    dataset['Cluster'] = kmeans.fit_predict(dataset[[cluster_col]])\n",
    "\n",
    "    def normalize(x):\n",
    "        return (x - x.median()) / x.std()\n",
    "\n",
    "    # Normalize the MFC within each bin to obtain the adjMFC\n",
    "    dataset['adjMFC'] = dataset.groupby('Cluster')[dayMFC].transform(normalize)\n",
    "\n",
    "    # Take relevant columns only\n",
    "    data = dataset[[immage_col, 'adjMFC', age_col, cluster_col, \"Cluster\"]].rename(columns={'adjMFC': response_col}).dropna()\n",
    "    # data.groupby(\"Cluster\").count()\n",
    "    strain = \"Influenza\"\n",
    "    strains = \"Influenza\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec9e662",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize clusters\n",
    "if bAdjustMFC:\n",
    "    custom_palette = {0: \"red\", 1: \"blue\", 2: \"green\"}\n",
    "    sorted_data = data.sort_values(cluster_col, ignore_index=True).reset_index()\n",
    "    sns.scatterplot(data=sorted_data, x=\"index\", y=cluster_col, hue=\"Cluster\", palette=custom_palette)\n",
    "    # plt.axhline(y=threshold, color=\"black\", linestyle=\"--\")\n",
    "    plt.title(f\"{cluster_col} clustered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f2a3e2",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Discard seroprotected subjects based on HAI > 40 threshold)\n",
    "if bDiscardSeroprotected:\n",
    "    HAI_threshold = 40\n",
    "    day0_mask = dataset[day_col] == day0\n",
    "    threshold_mask = dataset[response_col ]> HAI_threshold\n",
    "\n",
    "    # Get a list of all protected patients\n",
    "    serprotected_subjects = dataset.loc[(day0_mask) & (threshold_mask)][uid_col].unique()\n",
    "    # keep only patients not in the serprotected_subjects list\n",
    "    dataset = dataset.loc[~dataset[uid_col].isin(serprotected_subjects)]\n",
    "    subjects_left = dataset[uid_col].unique()\n",
    "    print(f\"Discarding {len(serprotected_subjects)} seroprotected subjects\")\n",
    "    print(f\"Subjects left: N={len(subjects_left)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a20dc",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "if bAdjustMFC == False:\n",
    "    # If not computing adjMFC, take a specific strain from the given post-vaccine day & assay\n",
    "    dayMFC_mask = dataset[day_col] == day\n",
    "    dataset = dataset.loc[(dayMFC_mask)].reset_index(drop=True)\n",
    "\n",
    "    # Somtimes there are multiple strains - so multiple rows per day\n",
    "    strains = dataset[strain_col].unique()\n",
    "    if len(strains) > 1:\n",
    "        dataset = dataset.loc[dataset[strain_col] == strains[strain_index]].reset_index(drop=True)\n",
    "\n",
    "    strains_t = dataset[strain_col].unique()\n",
    "    assert len(strains_t) == 1\n",
    "    strain = strains_t[0]\n",
    "\n",
    "    dataset = remove_duplicate_accessions(dataset, immage_col, uid_col)\n",
    "\n",
    "    # Take relevant columns only\n",
    "    data = dataset[[immage_col, response_col, age_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663ca686",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Keep older subjects only, since that's what's actually more interesting, and may show IMMAGE's advantage\n",
    "age_threshlod = 60\n",
    "if bOlderOnly == True:\n",
    "    young_subjects = data.loc[data[age_col] < age_threshlod]\n",
    "    data = data.loc[data[age_col] >= age_threshlod]\n",
    "    if len(data) == 0:\n",
    "        raise(Exception(\"No subjects over the age of {age_threshlod}. Exiting.\"))\n",
    "    print(f\"Discarding {len(young_subjects)} seroprotected subjects\")\n",
    "    print(f\"Subjects left: N={len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884a015b",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Dataset & Strain info\n",
    "\n",
    "age_restrict_str = f\", Subjects over the age of {age_threshlod}\" if bOlderOnly else \"\"\n",
    "day_str = \"Adjusted MFC\" if bAdjustMFC else f\"day: {day}\"\n",
    "\n",
    "md(f\"\"\"### Analysis for dataset: {dataset_name}, strain: {strain}, {day_str}{age_restrict_str}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e45fc6",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "md(\n",
    "    f\"\"\"Working with dataset: {dataset_name}, strain: {strain}, {day_str}\\n\n",
    "Total subjects in study: N = {data.shape[0]}\\n\n",
    "Other strains in this study: {strains}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9adec6a",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Get a boolean map of sub and super threshold values\n",
    "low_response_thr = data[[response_col]].quantile(q=0.3).item()\n",
    "\n",
    "# Generate labels\n",
    "# Note that we define y=1 for all responses <= 30th percentile (and not <)\n",
    "# Also note that we defined y=1 as *non* responders, since later on that's what we'll care about detecting\n",
    "\n",
    "data[\"y\"] = data[response_col].apply(lambda x: 1 if x <= low_response_thr else 0)\n",
    "\n",
    "# Add a text label for plot legends\n",
    "data[\"Label text\"] = data[\"y\"].apply(lambda x: \"Responders\" if x == 0 else \"Non-Responders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9853028",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Dynamic ranges of IMMAGE, response, and age values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751ba5b2",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "papermill": {},
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot IMMAGE, response, and age values to look at the dynamic range\n",
    "from scipy.stats import probplot\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(18, 6))  # Create a figure with two subplots side by side\n",
    "\n",
    "sns.histplot(data=data, x=immage_col, bins=50, ax=axs[0, 0])\n",
    "sns.boxplot(data=data, x=immage_col, ax=axs[1, 0], fill=False)\n",
    "# axs[0].set_title('Box Plot')\n",
    "axs[0, 0].set_title(f\" {immage_col}\")\n",
    "\n",
    "sns.histplot(data=data, x=response_col, bins=50, ax=axs[0, 1])\n",
    "sns.boxplot(data=data, x=response_col, ax=axs[1, 1], fill=False)\n",
    "# axs[1].set_title('Box Plot')\n",
    "axs[0, 1].set_title(f\" {response_col}\")\n",
    "\n",
    "sns.histplot(data=data, x=age_col, bins=50, ax=axs[0, 2])\n",
    "sns.boxplot(data=data, x=age_col, ax=axs[1, 2], fill=False)\n",
    "# axs[1].set_title('Box Plot')\n",
    "axs[0, 2].set_title(f\" {age_col}\")\n",
    "\n",
    "plt.tight_layout(pad=3.0)  # Adjust the layout so everything fits without overlap\n",
    "fig.suptitle(f\"Values Distribution in {dataset_name}, strain: {strain}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c919b368",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Classifying with logistic regression - fit on the entire dataset\n",
    "from math import log\n",
    "\n",
    "\n",
    "def get_threshold_from_probability(prob, intercept, slope):\n",
    "    return -1 * (log(1 / prob - 1) + intercept) / slope\n",
    "\n",
    "\n",
    "log_regress_immage = LogisticRegression()\n",
    "log_regress_age = LogisticRegression()\n",
    "log_regress_combined = LogisticRegression()\n",
    "\n",
    "# Train a classifier based on immage and on age for comparison\n",
    "log_regress_immage.fit(data[[immage_col]], data[\"y\"])\n",
    "log_regress_age.fit(data[[age_col]], data[\"y\"])\n",
    "log_regress_combined.fit(data[[immage_col, age_col]], data[\"y\"])\n",
    "\n",
    "non_responder_col = \"p_non_responder\"\n",
    "non_responder_col_age = \"p_non_responder_age\"\n",
    "non_responder_col_combined = \"p_non_responder_combined\"\n",
    "\n",
    "# data.reset_index(in_place=True, drop=True)\n",
    "\n",
    "proba = pd.DataFrame(log_regress_immage.predict_proba(data[[immage_col]]))\n",
    "data[non_responder_col] = proba[1]\n",
    "proba = pd.DataFrame(log_regress_age.predict_proba(data[[age_col]]))\n",
    "data[non_responder_col_age] = proba[1]\n",
    "proba = pd.DataFrame(log_regress_combined.predict_proba(data[[immage_col, age_col]]))\n",
    "data[non_responder_col_combined] = proba[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4628ed8c",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define auxilary functions\n",
    "from sklearn.metrics import auc, roc_auc_score, precision_recall_curve\n",
    "from math import log\n",
    "\n",
    "\n",
    "def calc_and_plot_prob_threshold(data, classifier, precision, recall, thresholds, prob_column, features=\"\"):\n",
    "    AUC = auc(recall, precision)\n",
    "    intercept = classifier.intercept_[0]\n",
    "    slope = classifier.coef_[0][0]\n",
    "\n",
    "    naive_classification_precision = data[\"y\"].mean()\n",
    "\n",
    "    # Identifying the optimal threshold (maximal F1 score)\n",
    "    beta = 0.7\n",
    "    F_scores = (1+pow(beta, 2))*(precision * recall)/(pow(beta, 2)*precision + recall)\n",
    "    optimal_idx = np.nanargmax(F_scores)\n",
    "    prob_threshold = thresholds[optimal_idx]\n",
    "    score = F_scores[optimal_idx]\n",
    "\n",
    "    # Calculate the cutoff value\n",
    "    feature_threshold = get_threshold_from_probability(\n",
    "        prob_threshold, intercept=intercept, slope=slope\n",
    "    )\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        1, 2, figsize=(16, 6)\n",
    "    )  # Creates a figure with two side-by-side subplots\n",
    "\n",
    "    # Plot PRC on the first subplot\n",
    "    axs[0].plot(recall, precision, label=f\"Precision-Recall curve (area = {AUC : 0.2f})\", color=\"#9b59b6\")\n",
    "    axs[0].axhline(y=naive_classification_precision, color=\"black\", linestyle=\"--\")\n",
    "    axs[0].plot(recall[optimal_idx], precision[optimal_idx], marker=\"o\", markersize=5, color=\"red\")\n",
    "    axs[0].set_xlim([0.0, 1.0])\n",
    "    axs[0].set_ylim([0.0, 1.05])\n",
    "    axs[0].set_xlabel(\"Recall\")\n",
    "    axs[0].set_ylabel(\"Precision\")\n",
    "    axs[0].set_title(\"Precision-Recall curve\")\n",
    "    axs[0].legend(loc=\"lower right\")\n",
    "\n",
    "    custom_palette = {\"Non-Responders\": \"orange\", \"Responders\": \"#3498db\"}\n",
    "\n",
    "    if len(features) == 1:\n",
    "        col_name = features[0]\n",
    "        # Plot sorted feature values vs Index on the second subplot\n",
    "        sorted_data = data.sort_values(col_name, ignore_index=True).reset_index()\n",
    "        sns.scatterplot(\n",
    "            ax=axs[1], data=sorted_data, x=\"index\", y=col_name, hue=\"Label text\", palette=custom_palette\n",
    "        )\n",
    "        axs[1].axhline(y=feature_threshold, color=\"black\", linestyle=\"--\")\n",
    "        axs[1].set_title(f\"Sorted {col_name} vs Index\")\n",
    "\n",
    "\n",
    "    else: # len(features) > 1\n",
    "        predicted_true = data.loc[data[prob_column] >= prob_threshold]\n",
    "\n",
    "        sns.scatterplot(\n",
    "            ax=axs[1], data=predicted_true, x=features[0], y=features[1], marker=\"x\", s=100, color=\"red\"\n",
    "        )\n",
    "        \n",
    "        sns.scatterplot(\n",
    "            ax=axs[1], data=data, x=features[0], y=features[1], hue=\"Label text\", palette=custom_palette\n",
    "        )\n",
    "        axs[1].set_title(f\"IMMAGE and Age, colour=response/non-response\")\n",
    "\n",
    "\n",
    "    fig.suptitle(f\"Probability-based threshold with PRC\\n({dataset_name}, {strain})\")\n",
    "    plt.tight_layout()  # Adjusts subplot params so that subplots fit into the figure area.\n",
    "    plt.show()\n",
    "\n",
    "    return (score, prob_threshold, feature_threshold, AUC)\n",
    "\n",
    "\n",
    "def get_classifier_stats_prob(data, prob_column, prob_threshold):\n",
    "    # Global measures (entire dataset)\n",
    "    optimal_pred = data[prob_column].apply(lambda x: 1 if x >= prob_threshold else 0)\n",
    "    test_accuracy = accuracy_score(data[\"y\"], optimal_pred)\n",
    "    # Performance above the prob_threshold\n",
    "    y_over_thr = data.loc[data[prob_column] >= prob_threshold, [\"y\"]]\n",
    "    non_response_rate_over_thr = y_over_thr.mean().y\n",
    "    y_under_thr = data.loc[data[prob_column] < prob_threshold, [\"y\"]]\n",
    "    non_response_rate_under_thr = y_under_thr.mean().y\n",
    "    return non_response_rate_over_thr, non_response_rate_under_thr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f739367",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "#### Thresholding based on logistic regression probabilties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e963c9a0",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### IMMAGE-based classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e668109",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "# Run for immage and age to compare\n",
    "# IMMAGE\n",
    "precision, recall, thresholds = precision_recall_curve(data[\"y\"], data[non_responder_col])\n",
    "immage_score, prob_threshold, immage_threshold, immage_auc = calc_and_plot_prob_threshold(\n",
    "    data, log_regress_immage, precision, recall, thresholds, non_responder_col, features=[immage_col]\n",
    ")\n",
    "non_response_rate_over_thr, non_response_rate_under_thr = get_classifier_stats_prob(\n",
    "    data, non_responder_col, prob_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247a6925",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Age-based classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea05e8d",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "# Age\n",
    "precision, recall, thresholds = precision_recall_curve(data[\"y\"], data[non_responder_col_age])\n",
    "age_score, prob_threshold_age, age_threshold, age_auc = calc_and_plot_prob_threshold(\n",
    "    data, log_regress_age, precision, recall, thresholds, non_responder_col_age, features=[age_col]\n",
    ")\n",
    "age_non_response_rate_over_thr, age_non_response_rate_under_thr = get_classifier_stats_prob(\n",
    "    data, non_responder_col_age, prob_threshold_age\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f4d1bf",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Age & IMMAGE combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6450b74",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "# Combined\n",
    "precision, recall, thresholds = precision_recall_curve(data[\"y\"], data[non_responder_col_combined])\n",
    "combined_score, prob_threshold_combined, _, combined_auc = calc_and_plot_prob_threshold(\n",
    "    data, log_regress_combined, precision, recall, thresholds, non_responder_col_combined, features=[immage_col, age_col]\n",
    ")\n",
    "combined_non_response_rate_over_thr, combined_non_response_rate_under_thr = (\n",
    "    get_classifier_stats_prob(data, non_responder_col_combined, prob_threshold_combined)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2734c56a",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Comparison of using the different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b366a205",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary = {\n",
    "    \"Variable\": [\"IMMAGE\", \"Age\", \"Multivariate\"],\n",
    "    # \"Optimal threshold\": [immage_threshold, age_threshold, prob_threshold_combined],\n",
    "    \"Optimal F-beta score\": [immage_score, age_score, combined_score],\n",
    "    # \"PRC AUC\": [immage_auc, age_auc, combined_auc],\n",
    "    # NR = Non-response\n",
    "    \"NR rate over threshold\": [\n",
    "        non_response_rate_over_thr,\n",
    "        age_non_response_rate_over_thr,\n",
    "        combined_non_response_rate_over_thr,\n",
    "    ],\n",
    "    \"NR rate under threshold\": [\n",
    "        non_response_rate_under_thr,\n",
    "        age_non_response_rate_under_thr,\n",
    "        combined_non_response_rate_under_thr,\n",
    "    ],\n",
    "    \n",
    "}\n",
    "\n",
    "df = pd.DataFrame(summary)\n",
    "df[\"Composite\"] = df[[\"Optimal F-beta score\", \"NR rate over threshold\"]].mean(axis=1)\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830ef384",
   "metadata": {
    "lines_to_next_cell": 0,
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_dict = {\n",
    "(\"F score\", \"IMMAGE\"): [immage_score],\n",
    "(\"F score\", \"Age\"): [age_score],\n",
    "(\"F score\", \"Multivariate\"): [combined_score],\n",
    "(\"NR rate over threshold\", \"IMMAGE\"): [non_response_rate_over_thr],\n",
    "(\"NR rate over threshold\", \"Age\"): [age_non_response_rate_over_thr],\n",
    "(\"NR rate over threshold\", \"Multivariate\"): [combined_non_response_rate_over_thr],\n",
    "(\"NR rate under threshold\", \"IMMAGE\"): [non_response_rate_under_thr],\n",
    "(\"NR rate under threshold\", \"Age\"): [age_non_response_rate_under_thr],\n",
    "(\"NR rate under threshold\", \"Multivariate\"): [combined_non_response_rate_under_thr],\n",
    "}\n",
    "\n",
    "# Create a MultiIndex\n",
    "multi_index = pd.MultiIndex.from_product([[\"F score\", \"NR rate over threshold\", \"NR rate under threshold\"], [\"IMMAGE\", \"Age\", \"Multivariate\"]])\n",
    "\n",
    "# Create the DataFrame\n",
    "summary = pd.DataFrame(summary_dict, columns=multi_index)\n",
    "summary[\"Composite\", \"IMMAGE\"] = summary[[(\"F score\", \"IMMAGE\"), (\"NR rate over threshold\", \"IMMAGE\")]].mean(axis=1)\n",
    "summary[\"Composite\", \"Age\"] = summary[[(\"F score\", \"Age\"), (\"NR rate over threshold\", \"Age\")]].mean(axis=1)\n",
    "summary[\"Composite\", \"Multivariate\"] = summary[[(\"F score\", \"Multivariate\"), (\"NR rate over threshold\", \"Multivariate\")]].mean(axis=1)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8187a5",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "input_path": "vaccines-4.ipynb",
   "output_path": "export/GSE59743.SDY400_A_California_7_2009_FC.HAI_discard_seroprotected.ipynb",
   "parameters": {
    "bAdjustMFC": false,
    "dataset_name": "GSE59743.SDY400",
    "day": "FC.HAI",
    "strain_index": 2
   },
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}