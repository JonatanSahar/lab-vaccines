{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d9f2d0",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "from jupyter_client import find_connection_file\n",
    "\n",
    "connection_file = find_connection_file()\n",
    "print(connection_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c73dd3",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "# Plotting related\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.tracebacklimit = 0\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# sns.set_palette([\"#3498db\", \"orange\"])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "\n",
    "# Scikit-learn related imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import randint, ttest_ind\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Jupyter-related\n",
    "from IPython.display import Markdown as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c583d0",
   "metadata": {
    "lines_to_next_cell": 2,
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change the current working directory\n",
    "os.chdir(\"/home/yonatan/Documents/projects/vaccines/code\")\n",
    "\n",
    "# maybe make plotly work\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f5fa7a",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "dataset_col = \"Dataset\"\n",
    "uid_col = \"uid\"\n",
    "age_col = \"Age\"\n",
    "day_col = \"Day\"\n",
    "response_col = \"Response\"\n",
    "immage_col = \"IMMAGE\"\n",
    "strain_col = \"Strain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6e92f8",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "def get_data_dir():\n",
    "    # Define the starting directory\n",
    "    current_dir = os.getcwd()\n",
    "\n",
    "    # Traverse up the directory tree until we find a directory named \"data\"\n",
    "    while current_dir != \"/\":\n",
    "        if \"data\" in os.listdir(current_dir):\n",
    "            data_dir = os.path.join(current_dir, \"data\")\n",
    "            return data_dir\n",
    "        current_dir = os.path.dirname(current_dir)\n",
    "    else:\n",
    "        print(\"Directory 'data' not found in the parent directories.\")\n",
    "        raise ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0883047a",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "# Read in Data and drop missing values\n",
    "data_dir = get_data_dir()\n",
    "df = pd.read_csv(os.path.join(data_dir, \"../data/all_vaccines.csv\"))\n",
    "df.dropna(inplace=True, subset=[immage_col, dataset_col, day_col, response_col])\n",
    "\n",
    "datasets = df\n",
    "dataset_names = df.Dataset.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbca0f4",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "# #### Distribution of studies' N values\n",
    "N_vals = df[[dataset_col, uid_col]].groupby(dataset_col, as_index=False)[uid_col].nunique()\n",
    "N_vals = N_vals.rename(columns={uid_col: \"N\"})\n",
    "# sns.histplot(N_vals.N)\n",
    "# plt.title(\"N values across studies\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b0cfe6",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "# Narrow N_v to large datasets only\n",
    "bNarrow = False\n",
    "large_N = N_vals.loc[N_vals[\"N\"] > 70]\n",
    "if bNarrow:\n",
    "    print(\"Narrowing to large datasets only\")\n",
    "    datasets = df.loc[df[\"Dataset\"].isin(large_N[\"Dataset\"])]\n",
    "\n",
    "dataset_names = datasets[\"Dataset\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f63b2d",
   "metadata": {
    "papermill": {},
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# These parameters are overridden by papermill\n",
    "strain_index = 0\n",
    "dataset_name = \"GSE41080.SDY212\"\n",
    "day = \"HAI.D28\"\n",
    "day0 = \"HAI.D0\"\n",
    "dayMFC = \"HAI.MFC\"\n",
    "\n",
    "bAdjustMFC = True\n",
    "bInfluenza = True\n",
    "bDiscardSeroprotected = False\n",
    "bOlderOnly = True\n",
    "\n",
    "influenza_dicts = [\n",
    "        {\"Dataset\": \"GSE41080.SDY212\", \"Days\": [\"FC.HAI\", \"HAI.D28\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"HAI.MFC\"},\n",
    "        {\"Dataset\": \"GSE48018.SDY1276\", \"Days\": [\"HAI.D28\", \"HAI.FC\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"HAI.MFC\"},\n",
    "        {\"Dataset\": \"GSE59654.SDY404\", \"Days\": [\"HAI.D28\", \"FC.HAI\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"HAI.MFC\"},\n",
    "        {\"Dataset\": \"GSE59743.SDY400\", \"Days\": [\"FC.HAI\", \"HAI.D28\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"HAI.MFC\"},\n",
    "        {\"Dataset\": \"SDY67\", \"Days\": [\"FC.D28.HAI\", \"HAI.D28\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"HAI.MFC\"},\n",
    "        {\"Dataset\": \"GSE59635.SDY63\", \"Days\": [\"FC\", \"HAI.D28\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"HAI.MFC\"},\n",
    "        # Five subjects only\n",
    "        # {\"Dataset\": \"GSE45735.SDY224\", \"Days\": [\"FC.HAI\", \"HAI.D21\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"HAI.MFC\"},\n",
    "\n",
    "        # Doesn't have a HAI measurement\n",
    "        # {\"Dataset\": \"GSE47353.SDY80\", \"Days\": [\"D70.nAb\", \"FC.D70.nAb\"], \"Day0\": \"D0.nAb\"},\n",
    "\n",
    "        # Need to calculate MFC individually for these\n",
    "        {\"Dataset\": \"GSE48023.SDY1276\", \"Days\": [\"HAI.FC\", \"HAI.D28\"], \"Day0\": \"HAI.D0\", \"DayMFC\": \"generated.HAI.MFC\"},\n",
    "        # {\"Dataset\": \"SDY296\", \"Days\": [\"D28.HAI\", \"FC.HAI\"], \"Day0\": \"D0.HAI\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454a6dee",
   "metadata": {
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "bAdjustMFC = False\n",
    "bDiscardSeroprotected = False\n",
    "bInfluenza = True\n",
    "bOlderOnly = True\n",
    "influenza_dicts = [\n",
    "    {\n",
    "        \"Dataset\": \"GSE41080.SDY212\",\n",
    "        \"Days\": [\"FC.HAI\", \"HAI.D28\"],\n",
    "        \"Day0\": \"HAI.D0\",\n",
    "        \"DayMFC\": \"HAI.MFC\",\n",
    "    },\n",
    "    {\n",
    "        \"Dataset\": \"GSE48018.SDY1276\",\n",
    "        \"Days\": [\"HAI.D28\", \"HAI.FC\"],\n",
    "        \"Day0\": \"HAI.D0\",\n",
    "        \"DayMFC\": \"HAI.MFC\",\n",
    "    },\n",
    "    {\n",
    "        \"Dataset\": \"GSE59654.SDY404\",\n",
    "        \"Days\": [\"HAI.D28\", \"FC.HAI\"],\n",
    "        \"Day0\": \"HAI.D0\",\n",
    "        \"DayMFC\": \"HAI.MFC\",\n",
    "    },\n",
    "    {\n",
    "        \"Dataset\": \"GSE59743.SDY400\",\n",
    "        \"Days\": [\"FC.HAI\", \"HAI.D28\"],\n",
    "        \"Day0\": \"HAI.D0\",\n",
    "        \"DayMFC\": \"HAI.MFC\",\n",
    "    },\n",
    "    {\n",
    "        \"Dataset\": \"SDY67\",\n",
    "        \"Days\": [\"FC.D28.HAI\", \"HAI.D28\"],\n",
    "        \"Day0\": \"HAI.D0\",\n",
    "        \"DayMFC\": \"HAI.MFC\",\n",
    "    },\n",
    "    {\n",
    "        \"Dataset\": \"GSE59635.SDY63\",\n",
    "        \"Days\": [\"FC\", \"HAI.D28\"],\n",
    "        \"Day0\": \"HAI.D0\",\n",
    "        \"DayMFC\": \"HAI.MFC\",\n",
    "    },\n",
    "    {\n",
    "        \"Dataset\": \"GSE45735.SDY224\",\n",
    "        \"Days\": [\"FC.HAI\", \"HAI.D21\"],\n",
    "        \"Day0\": \"HAI.D0\",\n",
    "        \"DayMFC\": \"HAI.MFC\",\n",
    "    },\n",
    "    {\"Dataset\": \"GSE47353.SDY80\", \"Days\": [\"D70.nAb\", \"FC.D70.nAb\"], \"Day0\": \"D0.nAb\"},\n",
    "    {\n",
    "        \"Dataset\": \"GSE48023.SDY1276\",\n",
    "        \"Days\": [\"HAI.FC\", \"HAI.D28\"],\n",
    "        \"Day0\": \"HAI.D0\",\n",
    "        \"DayMFC\": \"HAI.MFC\",\n",
    "    },\n",
    "    {\"Dataset\": \"SDY296\", \"Days\": [\"D28.HAI\", \"FC.HAI\"], \"Day0\": \"D0.HAI\"},\n",
    "]\n",
    "dataset_name = \"GSE59635.SDY63\"\n",
    "strain_index = 0\n",
    "day = \"FC\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ac340e",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "bInfluenza = True\n",
    "if bInfluenza:   \n",
    "    print(\"Working with Influenza datasets only\")\n",
    "    tmp_df = pd.DataFrame(influenza_dicts)\n",
    "    datasets = df.loc[df[\"Dataset\"].isin(tmp_df[\"Dataset\"])]\n",
    "    dataset_names = datasets[\"Dataset\"].unique()\n",
    "    tmp_df['Days'] = tmp_df['Days'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)  # Convert list to string for display\n",
    "    # print(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6051e8ad",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "# Examine available days per dataset\n",
    "# days = (\n",
    "#     datasets[[dataset_col, day_col]].groupby(dataset_col, as_index=False)[day_col].unique()\n",
    "# )\n",
    "\n",
    "# with pd.option_context('display.max_colwidth', None):\n",
    "#     for index, row in days.iterrows():\n",
    "#         print(f\"\\\"{row['Dataset']}\\\": {row['Day']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f22225",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Narrow a specific datset\n",
    "name_mask = datasets[dataset_col] == dataset_name\n",
    "dataset = datasets.loc[name_mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f734cd6",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate MFC for datasets which don't have it.\n",
    "# Need to normalize day0 and then.. Look at the paper\n",
    "# day_mask = dataset[day_col] == day\n",
    "# t = dataset.loc[day_mask]\n",
    "# t = dataset.groupby(uid_col)[response_col].max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1aaf38",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pivot the dataset such that different days' samples appear in their own columns, witn NaN where there are missing samples\n",
    "t = dataset[[dataset_col, uid_col, age_col, immage_col, \"geo_accession\", day_col, response_col]]\n",
    "pivot_t = t.pivot_table(index=uid_col, columns=day_col, values=response_col, aggfunc='first')\n",
    "age_t = dataset[['uid', 'Age']].drop_duplicates()\n",
    "\n",
    "# Average IMMAGE values across geo_accessions (if they exist) and merge\n",
    "immage_t = t.groupby('uid')[immage_col].mean()\n",
    "tmp_t = age_t.merge(immage_t, on='uid', how='left').drop_duplicates()\n",
    "pivot_t = tmp_t.merge(pivot_t, on='uid', how='left')\n",
    "\n",
    "# Reset index to make uid a column again\n",
    "pivot_t.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Remove the name of the columns and index name\n",
    "pivot_t.columns.name = None\n",
    "pivot_t.index.name = None\n",
    "\n",
    "# TODO complege generating MFC for this dataset\n",
    "if dataset_name == 'SDY296' or dataset_name == 'GSE48023.SDY1276':\n",
    "    dataset = dataset.loc[(~pivot_t[day0].isna()) & (~pivot_t[\"FC.HAI\"].isna())]\n",
    "    pivot_t[dayMFC] = pivot_t[day] / pivot_t[day0]\n",
    "\n",
    "# Currently only used by AdjustMFC branch. TODO: convert the \"regular\" to use it too\n",
    "pivot_dataset = pivot_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558e291c",
   "metadata": {
    "lines_to_next_cell": 1,
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sometimes there are multiple geo_accession numbers, like in GSE48018.SDY1276.\n",
    "# Average the IMMAGE, since all else is the same\n",
    "def remove_duplicate_accessions(dataset, immage_col, uid_col):\n",
    "    first_uid = dataset.iloc[0][uid_col]\n",
    "    accessions = dataset[dataset[uid_col] == first_uid][\"geo_accession\"].unique()\n",
    "    if len(accessions) > 1:\n",
    "        # print(f\"Multiple accession detected, Collapsing by averaging on IMMAGE value\")\n",
    "        dataset = dataset.groupby(uid_col, as_index=False).agg({immage_col: \"mean\", **{col: \"first\" for col in dataset.columns if col not in [uid_col, immage_col]},})\n",
    "\n",
    "    accessions = dataset[dataset[uid_col] == first_uid][\"geo_accession\"].unique()\n",
    "    assert len(accessions) == 1\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a91dac",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# Use adjusted MFC (HAI) as per John Tsang\n",
    "cluster_col = day0\n",
    "if bAdjustMFC:\n",
    "    exit(1)\n",
    "    dataset = pivot_dataset[[uid_col, immage_col, age_col, day0, dayMFC]]\n",
    "    print(\"Preprocessing dataset, computing adjusted MFC (HAI)\")\n",
    "    dataset = dataset.loc[(~pivot_t[day0].isna()) & (~pivot_t[dayMFC].isna())]\n",
    "\n",
    "    mean = dataset[day0].mean()\n",
    "    std = dataset[day0].std()\n",
    "    threshold = 3 * std\n",
    "    dataset = dataset[(dataset[day0] >= mean - threshold) & (dataset[day0] <= mean + threshold)]\n",
    "\n",
    "    # Bin subjects into 2-3 bins using k-means clustering\n",
    "    kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "    dataset['Cluster'] = kmeans.fit_predict(dataset[[cluster_col]])\n",
    "\n",
    "    def normalize(x):\n",
    "        return (x - x.median()) / x.std()\n",
    "\n",
    "    # Normalize the MFC within each bin to obtain the adjMFC\n",
    "    dataset['adjMFC'] = dataset.groupby('Cluster')[dayMFC].transform(normalize)\n",
    "\n",
    "    # Take relevant columns only\n",
    "    data = dataset[[immage_col, 'adjMFC', age_col, cluster_col, \"Cluster\"]].rename(columns={'adjMFC': response_col}).dropna()\n",
    "    # data.groupby(\"Cluster\").count()\n",
    "    strain = \"Influenza\"\n",
    "    strains = \"Influenza\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba9cbbd",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize clusters\n",
    "if bAdjustMFC:\n",
    "    custom_palette = {0: \"red\", 1: \"blue\", 2: \"green\"}\n",
    "    sorted_data = data.sort_values(cluster_col, ignore_index=True).reset_index()\n",
    "    sns.scatterplot(data=sorted_data, x=\"index\", y=cluster_col, hue=\"Cluster\", palette=custom_palette)\n",
    "    # plt.axhline(y=threshold, color=\"black\", linestyle=\"--\")\n",
    "    plt.title(f\"{cluster_col} clustered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c665a089",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Discard seroprotected subjects based on HAI > 40 threshold)\n",
    "if bDiscardSeroprotected:\n",
    "    HAI_threshold = 40\n",
    "    day0_mask = dataset[day_col] == day0\n",
    "    threshold_mask = dataset[response_col ]> HAI_threshold\n",
    "\n",
    "    # Get a list of all protected patients\n",
    "    serprotected_subjects = dataset.loc[(day0_mask) & (threshold_mask)][uid_col].unique()\n",
    "    # keep only patients not in the serprotected_subjects list\n",
    "    dataset = dataset.loc[~dataset[uid_col].isin(serprotected_subjects)]\n",
    "    subjects_left = dataset[uid_col].unique()\n",
    "    print(f\"Discarding {len(serprotected_subjects)} seroprotected subjects\")\n",
    "    print(f\"Subjects left: N={len(subjects_left)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd54e9d",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "if bAdjustMFC == False:\n",
    "    # If not computing adjMFC, take a specific strain from the given post-vaccine day & assay\n",
    "    dayMFC_mask = dataset[day_col] == day\n",
    "    dataset = dataset.loc[(dayMFC_mask)].reset_index(drop=True)\n",
    "\n",
    "    # Somtimes there are multiple strains - so multiple rows per day\n",
    "    strains = dataset[strain_col].unique()\n",
    "    if len(strains) > 1:\n",
    "        dataset = dataset.loc[dataset[strain_col] == strains[strain_index]].reset_index(drop=True)\n",
    "\n",
    "    strains_t = dataset[strain_col].unique()\n",
    "    assert len(strains_t) == 1\n",
    "    strain = strains_t[0]\n",
    "\n",
    "    dataset = remove_duplicate_accessions(dataset, immage_col, uid_col)\n",
    "\n",
    "    # Take relevant columns only\n",
    "    data = dataset[[immage_col, response_col, age_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe64a51",
   "metadata": {
    "lines_to_next_cell": 0,
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Keep older subjects only, since that's what's actually more interesting, and may show IMMAGE's advantage\n",
    "age_threshlod = 60\n",
    "if bOlderOnly == True:\n",
    "    data = data.loc[data[age_col] > age_threshlod]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6e81d1",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### Dataset & Strain info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab3fac4",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "age_restrict_str = f\", Subjects over the age of {age_threshlod}\" if bOlderOnly else \"\"\n",
    "day_str = \"Adjusted MFC\" if bAdjustMFC else f\"day: {day}\"\n",
    "\n",
    "md(f\"\"\"## Analysis for dataset: {dataset_name}, strain: {strain}, {day_str}{age_restrict_str}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d031b7",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "md(\n",
    "    f\"\"\"Working with dataset: {dataset_name}, strain: {strain}, {day_str}\\n\n",
    "Total subjects in study: N = {data.shape[0]}\\n\n",
    "Other strains in this study: {strains}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be32164",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Get a boolean map of sub and super threshold values\n",
    "low_response_thr = data[[response_col]].quantile(q=0.3).item()\n",
    "\n",
    "# Generate labels\n",
    "# Note that we define y=1 for all responses < 30th percentile (and not <=)\n",
    "# Also note that we defined y=1 as *non* responders, since later on that's what we'll care most about detecting\n",
    "\n",
    "data[\"y\"] = data[response_col].apply(lambda x: 1 if x < low_response_thr else 0)\n",
    "\n",
    "# Add a text label for plot legends\n",
    "data[\"Label text\"] = data[\"y\"].apply(lambda x: \"Responders\" if x == 0 else \"Non-Responders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc32a683",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Dynamic ranges of IMMAGE, response, and age values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a34736",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "papermill": {},
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot IMMAGE, response, and age values to look at the dynamic range\n",
    "from scipy.stats import probplot\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(18, 6))  # Create a figure with two subplots side by side\n",
    "\n",
    "sns.histplot(data=data, x=immage_col, bins=50, ax=axs[0, 0])\n",
    "sns.boxplot(data=data, x=immage_col, ax=axs[1, 0], fill=False)\n",
    "# axs[0].set_title('Box Plot')\n",
    "axs[0, 0].set_title(f\" {immage_col}\")\n",
    "\n",
    "sns.histplot(data=data, x=response_col, bins=50, ax=axs[0, 1])\n",
    "sns.boxplot(data=data, x=response_col, ax=axs[1, 1], fill=False)\n",
    "# axs[1].set_title('Box Plot')\n",
    "axs[0, 1].set_title(f\" {response_col}\")\n",
    "\n",
    "sns.histplot(data=data, x=age_col, bins=50, ax=axs[0, 2])\n",
    "sns.boxplot(data=data, x=age_col, ax=axs[1, 2], fill=False)\n",
    "# axs[1].set_title('Box Plot')\n",
    "axs[0, 2].set_title(f\" {age_col}\")\n",
    "\n",
    "plt.tight_layout(pad=3.0)  # Adjust the layout so everything fits without overlap\n",
    "fig.suptitle(f\"Values Distribution in {dataset_name}, strain: {strain}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637b6b05",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Classifying with logistic regression - fit on the entire dataset\n",
    "from math import log\n",
    "\n",
    "\n",
    "def get_threshold_from_probability(prob, intercept, slope):\n",
    "    return -1 * (log(1 / prob - 1) + intercept) / slope\n",
    "\n",
    "\n",
    "log_regress_immage = LogisticRegression()\n",
    "log_regress_age = LogisticRegression()\n",
    "log_regress_combined = LogisticRegression()\n",
    "\n",
    "# Train a classifier based on immage and on age for comparison\n",
    "log_regress_immage.fit(data[[immage_col]], data[\"y\"])\n",
    "log_regress_age.fit(data[[age_col]], data[\"y\"])\n",
    "log_regress_combined.fit(data[[immage_col, age_col]], data[\"y\"])\n",
    "\n",
    "non_responder_col = \"p_non_responder\"\n",
    "non_responder_col_age = \"p_non_responder_age\"\n",
    "non_responder_col_combined = \"p_non_responder_combined\"\n",
    "\n",
    "# data.reset_index(in_place=True, drop=True)\n",
    "\n",
    "proba = pd.DataFrame(log_regress_immage.predict_proba(data[[immage_col]]))\n",
    "data[non_responder_col] = proba[1]\n",
    "proba = pd.DataFrame(log_regress_age.predict_proba(data[[age_col]]))\n",
    "data[non_responder_col_age] = proba[1]\n",
    "proba = pd.DataFrame(log_regress_combined.predict_proba(data[[immage_col, age_col]]))\n",
    "data[non_responder_col_combined] = proba[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8539638",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define auxilary functions\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve\n",
    "from math import log\n",
    "\n",
    "\n",
    "def calc_and_plot_prob_threshold(data, classifier, fpr, tpr, thresholds, col_name=\"\"):\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    intercept = classifier.intercept_[0]\n",
    "    slope = classifier.coef_[0][0]\n",
    "\n",
    "    # Identifying the optimal threshold (using Youden’s Index)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    prob_threshold = thresholds[optimal_idx]\n",
    "\n",
    "    # Calculate the cutoff value\n",
    "    feature_threshold = get_threshold_from_probability(\n",
    "        prob_threshold, intercept=intercept, slope=slope\n",
    "    )\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        1, 2, figsize=(16, 6)\n",
    "    )  # Creates a figure with two side-by-side subplots\n",
    "\n",
    "    # Plot ROC curve on the first subplot\n",
    "    axs[0].plot(fpr, tpr, label=f\"ROC curve (area = {roc_auc : 0.2f})\", color=\"#9b59b6\")\n",
    "    axs[0].plot([0, 1], [0, 1], \"k--\")  # Random chance line\n",
    "    axs[0].plot(fpr[optimal_idx], tpr[optimal_idx], marker=\"o\", markersize=5, color=\"red\")\n",
    "    axs[0].set_xlim([0.0, 1.0])\n",
    "    axs[0].set_ylim([0.0, 1.05])\n",
    "    axs[0].set_xlabel(\"False Positive Rate\")\n",
    "    axs[0].set_ylabel(\"True Positive Rate\")\n",
    "    axs[0].set_title(\"ROC curve\")\n",
    "    axs[0].legend(loc=\"lower right\")\n",
    "\n",
    "    # Plot sorted feature values vs Index on the second subplot\n",
    "    custom_palette = {\"Non-Responders\": \"orange\", \"Responders\": \"#3498db\"}\n",
    "    sorted_data = data.sort_values(col_name, ignore_index=True).reset_index()\n",
    "    sns.scatterplot(\n",
    "        ax=axs[1], data=sorted_data, x=\"index\", y=col_name, hue=\"Label text\", palette=custom_palette\n",
    "    )\n",
    "    axs[1].axhline(y=feature_threshold, color=\"black\", linestyle=\"--\")\n",
    "    axs[1].set_title(f\"Sorted {col_name} vs Index\")\n",
    "\n",
    "    fig.suptitle(f\"Probability-based threshold with ROC\\n({dataset_name}, {strain})\")\n",
    "    plt.tight_layout()  # Adjusts subplot params so that subplots fit into the figure area.\n",
    "    plt.show()\n",
    "\n",
    "    return (prob_threshold, feature_threshold, roc_auc)\n",
    "\n",
    "\n",
    "def calc_and_plot_prob_threshold_multivar(data, classifier, fpr, tpr, thresholds, features=\"\"):\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    intercept = classifier.intercept_[0]\n",
    "    slope = classifier.coef_[0][0]\n",
    "\n",
    "    # Identifying the optimal threshold (using Youden’s Index)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    prob_threshold = thresholds[optimal_idx]\n",
    "\n",
    "    # Calculate the cutoff value\n",
    "    feature_threshold = get_threshold_from_probability(\n",
    "        prob_threshold, intercept=intercept, slope=slope\n",
    "    )\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    # Plot ROC curve on the first subplot\n",
    "    axs[0].plot(fpr, tpr, color=\"#9b59b6\", label=f\"ROC curve (area = {roc_auc : 0.2f})\")\n",
    "    axs[0].plot([0, 1], [0, 1], \"k--\")  # Random chance line\n",
    "    axs[0].plot(fpr[optimal_idx], tpr[optimal_idx], marker=\"o\", markersize=5, color=\"red\")\n",
    "    axs[0].set_xlim([0.0, 1.0])\n",
    "    axs[0].set_ylim([0.0, 1.05])\n",
    "    axs[0].set_xlabel(\"False Positive Rate\")\n",
    "    axs[0].set_ylabel(\"True Positive Rate\")\n",
    "    axs[0].set_title(\"ROC curve\")\n",
    "    axs[0].legend(loc=\"lower right\")\n",
    "\n",
    "    # Plot sorted IMMAGE values vs Index on the second subplot\n",
    "    # Define a custom color palette\n",
    "    custom_palette = {\"Non-Responders\": \"orange\", \"Responders\": \"#3498db\"}\n",
    "    sns.scatterplot(\n",
    "        ax=axs[1], data=data, x=features[0], y=features[1], hue=\"Label text\", palette=custom_palette\n",
    "    )\n",
    "    # axs[1].axhline(y=feature_threshold, color=\"black\", linestyle=\"--\")\n",
    "    axs[1].set_title(f\"IMMAGE and Age labels\")\n",
    "\n",
    "    fig.suptitle(f\"Probability-based threshold with ROC\\n({dataset_name}, {strain})\")\n",
    "    plt.tight_layout()  # Adjusts subplot params so that subplots fit into the figure area.\n",
    "    plt.show()\n",
    "\n",
    "    return (\n",
    "        prob_threshold,\n",
    "        feature_threshold,\n",
    "        roc_auc,\n",
    "    )  # feature threshold is meaningless for the multivariate case\n",
    "\n",
    "\n",
    "def get_classifier_stats_prob(data, prob_column, prob_threshold):\n",
    "    # Global measures (entire dataset)\n",
    "    optimal_pred = data[prob_column].apply(lambda x: 1 if x >= prob_threshold else 0)\n",
    "    test_accuracy = accuracy_score(data[\"y\"], optimal_pred)\n",
    "    # Performance above the prob_threshold\n",
    "    y_over_thr = data.loc[data[prob_column] >= prob_threshold, [\"y\"]]\n",
    "    non_response_rate_over_thr = y_over_thr.mean().y\n",
    "    y_under_thr = data.loc[data[prob_column] < prob_threshold, [\"y\"]]\n",
    "    non_response_rate_under_thr = y_under_thr.mean().y\n",
    "    return non_response_rate_over_thr, non_response_rate_under_thr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf041f6",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "#### Thresholding based on logistic regression probabilties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab700e7",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### IMMAGE-based classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d0f12a",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "# Run for immage and age to compare\n",
    "# IMMAGE\n",
    "fpr, tpr, thresholds = roc_curve(data[\"y\"], data[non_responder_col])\n",
    "prob_threshold, immage_threshold, immage_roc_auc = calc_and_plot_prob_threshold(\n",
    "    data, log_regress_immage, fpr, tpr, thresholds, col_name=immage_col\n",
    ")\n",
    "non_response_rate_over_thr, non_response_rate_under_thr = get_classifier_stats_prob(\n",
    "    data, non_responder_col, prob_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430d29e4",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Age-based classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64362c0a",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "# Age\n",
    "fpr, tpr, thresholds = roc_curve(data[\"y\"], data[non_responder_col_age])\n",
    "prob_threshold_age, age_threshold, age_roc_auc = calc_and_plot_prob_threshold(\n",
    "    data, log_regress_age, fpr, tpr, thresholds, col_name=age_col\n",
    ")\n",
    "age_non_response_rate_over_thr, age_non_response_rate_under_thr = get_classifier_stats_prob(\n",
    "    data, non_responder_col_age, prob_threshold_age\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa66216",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Age & IMMAGE combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc9ea6b",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "# Combined\n",
    "fpr, tpr, thresholds = roc_curve(data[\"y\"], data[non_responder_col_combined])\n",
    "prob_threshold_combined, _, combined_roc_auc = calc_and_plot_prob_threshold_multivar(\n",
    "    data, log_regress_combined, fpr, tpr, thresholds, features=[immage_col, age_col]\n",
    ")\n",
    "combined_non_response_rate_over_thr, combined_non_response_rate_under_thr = (\n",
    "    get_classifier_stats_prob(data, non_responder_col_combined, prob_threshold_combined)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedad3c9",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Comparison of using the different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b0efb0",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%script true\n",
    "print(\n",
    "    f'''IMMAGE:\n",
    "    Optimal threshold: {immage_threshold : 0.2f} (IMMAGE value)\n",
    "    Non-responder rate:\n",
    "      over threshold: {non_response_rate_over_thr : 0.2f}\n",
    "      under threshold: {non_response_rate_under_thr : 0.2f}\\n'''\n",
    ");\n",
    "print(\n",
    "    f'''Age:\n",
    "    Optimal threshold: {age_threshold : 0.2f} (Age)\n",
    "    Non-responder rate:\n",
    "      over threshold: {age_non_response_rate_over_thr : 0.2f}\n",
    "      under threshold: {age_non_response_rate_under_thr : 0.2f}\\n'''\n",
    ");\n",
    "print(\n",
    "    f'''Multivariate:\n",
    "    Optimal threshold: {prob_threshold_combined : 0.2f} (probability)\n",
    "    Non-responder rate:\n",
    "    over threshold: {combined_non_response_rate_over_thr : 0.2f}\n",
    "    under threshold: {combined_non_response_rate_under_thr : 0.2f}\\n'''\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c7a687",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary = {\n",
    "    \"Variable\": [\"IMMAGE\", \"Age\", \"Multivariate\"],\n",
    "    \"Optimal threshold\": [immage_threshold, age_threshold, prob_threshold_combined],\n",
    "    \"ROC AUC\": [immage_roc_auc, age_roc_auc, combined_roc_auc],\n",
    "    \"Non response over threshold\": [\n",
    "        non_response_rate_over_thr,\n",
    "        age_non_response_rate_over_thr,\n",
    "        combined_non_response_rate_over_thr,\n",
    "    ],\n",
    "    \"Non response under threshold\": [\n",
    "        non_response_rate_under_thr,\n",
    "        age_non_response_rate_under_thr,\n",
    "        combined_non_response_rate_under_thr,\n",
    "    ],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(summary)\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56c80be",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "papermill": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Sliding window analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dffcf1",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sliding window instead of bins, plotting non-reponder rate vs window start\n",
    "def generate_windows(data, feature_col, num_units, num_units_per_window):\n",
    "    \"\"\"\n",
    "    Generates window start and end points based on the specified feature column in the data.\n",
    "    \"\"\"\n",
    "    window_starts = np.linspace(\n",
    "        start=data[feature_col].min(), stop=data[feature_col].max(), num=num_units\n",
    "    )\n",
    "    window_size = (\n",
    "        (data[feature_col].max() - data[feature_col].min()) / num_units * num_units_per_window\n",
    "    )\n",
    "    window_starts = pd.Series(window_starts)\n",
    "    windows = pd.DataFrame({\"start\": window_starts[:-num_units_per_window].reset_index(drop=True), \"end\": window_starts[num_units_per_window:].reset_index(drop=True)})\n",
    "    return windows, window_size\n",
    "\n",
    "\n",
    "def calculate_rates(data, windows, feature_col):\n",
    "    \"\"\"\n",
    "    Calculates the rate for each window based on the occurrences within that window: non-reponders/all-subjects-in-window.\n",
    "    \"\"\"\n",
    "    rates = []\n",
    "\n",
    "    for i, start, end in windows.itertuples():\n",
    "        over = data[feature_col] >= windows[\"start\"][i]\n",
    "        under = data[feature_col] < windows[\"end\"][i]\n",
    "        rates.append(data.loc[(over & under), \"y\"].mean())\n",
    "\n",
    "    rates = pd.Series(rates).fillna(0)\n",
    "    windows[\"rate\"] = rates\n",
    "\n",
    "    return windows\n",
    "\n",
    "\n",
    "def calculate_rates_total(data, windows, feature_col):\n",
    "    \"\"\"\n",
    "        Calculates the rate for each window based on the relation of each window to total population: window-non-reponders/all-non-responders.\n",
    "    _\"\"\"\n",
    "    rates = []\n",
    "    total_non_responders = data[\"y\"].sum()\n",
    "\n",
    "    for i, start, end in windows.itertuples():\n",
    "        over = data[feature_col] >= windows[\"start\"][i]\n",
    "        under = data[feature_col] < windows[\"end\"][i]\n",
    "        rates.append(data.loc[(over & under), \"y\"].sum() / total_non_responders)\n",
    "\n",
    "    rates = pd.Series(rates).fillna(0)\n",
    "    windows[\"rate\"] = rates\n",
    "\n",
    "    return windows\n",
    "\n",
    "\n",
    "def generate_windows_and_rates(data, feature_col, num_units, num_units_per_window, total=False):\n",
    "    windows, window_size = generate_windows(data, feature_col, num_units, num_units_per_window)\n",
    "    if total:\n",
    "        windows = calculate_rates_total(data, windows, feature_col)\n",
    "    else:\n",
    "        windows = calculate_rates(data, windows, feature_col)\n",
    "\n",
    "    return windows, window_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314a588f",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "##### \"Local\" metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae6fdf2",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "num_units = 100\n",
    "feature_cols = [immage_col, age_col]\n",
    "num_features = len(feature_cols)\n",
    "\n",
    "# Plot windows with \"local\" rate\n",
    "fig, axs = plt.subplots(1, num_features, figsize=(5 * num_features, 5))\n",
    "\n",
    "for i, feature_col in enumerate(feature_cols):\n",
    "    windows, window_size = generate_windows_and_rates(data, feature_col, num_units, 20, total=False)\n",
    "    sns.lineplot(data=windows, x=\"start\", y=\"rate\", ax=axs[i])\n",
    "    axs[i].axhline(y=0.5, color=\"black\", linestyle=\"--\")\n",
    "    axs[i].set_title(f\"Window size: {window_size:.2f} {feature_col} units\")\n",
    "    axs[i].set_xlabel(\"Start\")\n",
    "    axs[i].set_ylabel(\"Rate\")\n",
    "\n",
    "fig.suptitle(\n",
    "    f\"\"\"Sliding window performance\n",
    "    Rate of non-responders vs feature values\n",
    "    ({dataset_name}, {strain})\"\"\"\n",
    ")\n",
    "plt.subplots_adjust(top=0.75)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d934c9d9",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "papermill": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "##### \"Global\" metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffa8ced",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "papermill": {},
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "noexport"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot windows with \"global\" rate\n",
    "fig, axs = plt.subplots(1, num_features, figsize=(5 * num_features, 5))\n",
    "\n",
    "for i, feature_col in enumerate(feature_cols):\n",
    "    windows, window_size = generate_windows_and_rates(data, feature_col, num_units, 20, total=True)\n",
    "    sns.lineplot(data=windows, x=\"start\", y=\"rate\", ax=axs[i])\n",
    "    axs[i].axhline(y=0.5, color=\"black\", linestyle=\"--\")\n",
    "    axs[i].set_title(f\"Window size: {window_size:.2f} {feature_col} units\")\n",
    "    axs[i].set_xlabel(\"Start\")\n",
    "    axs[i].set_ylabel(\"Rate\")\n",
    "\n",
    "fig.suptitle(\n",
    "    f\"\"\"Sliding window performance\n",
    "    Global rate of non-responders vs feature values\n",
    "    ({dataset_name}, {strain})\"\"\"\n",
    ")\n",
    "plt.subplots_adjust(top=0.75)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ba357b",
   "metadata": {
    "editable": true,
    "papermill": {},
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2D sliding windows - not worth the time it take to make this work\n",
    "feature1 = immage_col\n",
    "feature2 = age_col\n",
    "f1_windows, size1 = generate_windows(data, feature1, 100, 20)\n",
    "f2_windows, size2 = generate_windows(data, feature2, 100, 20)\n",
    "windows = pd.concat([f1_windows, f2_windows], keys=[\"f1_windows\", \"f2_windows\"], axis=1)\n",
    "rates = []\n",
    "for i, start1, end1, start2, end2 in windows.itertuples():\n",
    "    over1 = data[feature1] >= start1\n",
    "    under1 = data[feature1] < end1\n",
    "    over2 = data[feature2] >= start2\n",
    "    under2 = data[feature2] < end2\n",
    "    # mean is summing the positive labels = # of positives and dividing by the total # of subjects in that group\n",
    "    rates.append(data.loc[(over1 & under1 & over2 & under2), \"y\"].mean())\n",
    "\n",
    "rates = pd.Series(rates).fillna(0)\n",
    "windows[\"rate\"] = rates\n",
    "# rate_matrix = data.groupby(['f1_bin', 'f2_bin'])[target].mean().unstack().fillna(0)\n",
    "\n",
    "\n",
    "def calculate_2d_rates(data, feature1, feature2, target, num_bins=10):\n",
    "    f1_windows = generate_windows(data, feature1, 100, 20)\n",
    "    f2_windows = generate_windows(data, feature2, 100, 20)\n",
    "    windows = pd.DataFrame({\"f1_windows\": f1_windows, \"f2_windows\": f2_windows})\n",
    "\n",
    "    for i, start1, end1, start2, end2 in windows.itertuples():\n",
    "        over1 = data[feature1] >= start1\n",
    "        under1 = data[feature1] < end1\n",
    "        over2 = data[feature2] >= start2\n",
    "        under2 = data[feature2] < end2\n",
    "        # mean is summing the positive labels = # of positives and dividing by the total # of subjects in that group\n",
    "        rates.append(data.loc[(over1 & under1 & over2 & under2), \"y\"].mean())\n",
    "\n",
    "    rates = pd.Series(rates).fillna(0)\n",
    "    windows[\"rate\"] = rates\n",
    "    rate_matrix = data.groupby([\"f1_bin\", \"f2_bin\"])\n",
    "\n",
    "    return rate_matrix\n",
    "\n",
    "\n",
    "def plot_2d_rates(rate_matrix):\n",
    "    # Plot as a heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(rate_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "    plt.title(\"Rate of Non-Responders by 2D Feature Bins\")\n",
    "    plt.xlabel(\"Feature 2 Bin\")\n",
    "    plt.ylabel(\"Feature 1 Bin\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Calculate and plot\n",
    "# rate_matrix = calculate_2d_rates(data, 'feature1', 'feature2', 'y', num_bins=5)\n",
    "# plot_2d_rates(rate_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "input_path": "vaccines-4.ipynb",
   "output_path": "export/GSE59635.SDY63_B_Brisbane_60_2008_FC_older-only.ipynb",
   "parameters": {
    "bAdjustMFC": false,
    "bDiscardSeroprotected": false,
    "bInfluenza": true,
    "bOlderOnly": true,
    "dataset_name": "GSE59635.SDY63",
    "day": "FC",
    "influenza_dicts": [
     {
      "Dataset": "GSE41080.SDY212",
      "Day0": "HAI.D0",
      "DayMFC": "HAI.MFC",
      "Days": [
       "FC.HAI",
       "HAI.D28"
      ]
     },
     {
      "Dataset": "GSE48018.SDY1276",
      "Day0": "HAI.D0",
      "DayMFC": "HAI.MFC",
      "Days": [
       "HAI.D28",
       "HAI.FC"
      ]
     },
     {
      "Dataset": "GSE59654.SDY404",
      "Day0": "HAI.D0",
      "DayMFC": "HAI.MFC",
      "Days": [
       "HAI.D28",
       "FC.HAI"
      ]
     },
     {
      "Dataset": "GSE59743.SDY400",
      "Day0": "HAI.D0",
      "DayMFC": "HAI.MFC",
      "Days": [
       "FC.HAI",
       "HAI.D28"
      ]
     },
     {
      "Dataset": "SDY67",
      "Day0": "HAI.D0",
      "DayMFC": "HAI.MFC",
      "Days": [
       "FC.D28.HAI",
       "HAI.D28"
      ]
     },
     {
      "Dataset": "GSE59635.SDY63",
      "Day0": "HAI.D0",
      "DayMFC": "HAI.MFC",
      "Days": [
       "FC",
       "HAI.D28"
      ]
     },
     {
      "Dataset": "GSE45735.SDY224",
      "Day0": "HAI.D0",
      "DayMFC": "HAI.MFC",
      "Days": [
       "FC.HAI",
       "HAI.D21"
      ]
     },
     {
      "Dataset": "GSE47353.SDY80",
      "Day0": "D0.nAb",
      "Days": [
       "D70.nAb",
       "FC.D70.nAb"
      ]
     },
     {
      "Dataset": "GSE48023.SDY1276",
      "Day0": "HAI.D0",
      "DayMFC": "HAI.MFC",
      "Days": [
       "HAI.FC",
       "HAI.D28"
      ]
     },
     {
      "Dataset": "SDY296",
      "Day0": "D0.HAI",
      "Days": [
       "D28.HAI",
       "FC.HAI"
      ]
     }
    ],
    "strain_index": 0
   },
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}